{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install torch\n",
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "# Configure hardware\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train, test, evaluation functions\n",
    "def train(dataloader, model, loss_fn, optimizer, quiet=False):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            losses.append(loss)\n",
    "            if not quiet:\n",
    "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    return np.mean(losses)\n",
    "\n",
    "def test(dataloader, model, loss_fn, quiet=False):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    if not quiet:\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return correct, test_loss\n",
    "\n",
    "def eval(train_dataloader, test_dataloader, model, loss_fn, optimizer, epochs, quiet=False):\n",
    "    overall_train_loss = []\n",
    "    overall_test_acc = []\n",
    "    overall_test_loss = []\n",
    "    for t in range(epochs):\n",
    "        if not quiet:\n",
    "            print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_loss = train(train_dataloader, model, loss_fn, optimizer, quiet=quiet)\n",
    "        test_acc, test_loss = test(test_dataloader, model, loss_fn, quiet=quiet)\n",
    "        overall_train_loss.append(train_loss)\n",
    "        overall_test_acc.append(test_acc)\n",
    "        overall_test_loss.append(test_loss)\n",
    "        if not quiet:\n",
    "            print(\"Done!\")\n",
    "    return pd.DataFrame({\n",
    "        'train loss' : overall_train_loss, \n",
    "        'test_acc' : overall_test_acc, \n",
    "        'test_loss' : overall_test_loss\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fully Connected Network Classifier on Fashion MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCNet(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (sequential): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "FCNet(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (sequential): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): SiLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): SiLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Fully connected network with variable activation function\n",
    "class FCNet(nn.Module):\n",
    "    def __init__(self, activation):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            activation(),\n",
    "            nn.Linear(512, 512),\n",
    "            activation(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.sequential(x)\n",
    "        return logits\n",
    "\n",
    "fcnet = FCNet(nn.ReLU).to(device)\n",
    "silunet = FCNet(nn.SiLU).to(device)\n",
    "\n",
    "print(fcnet)\n",
    "print(silunet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Download training and test data from PyTorch open datasets and create dataloaders\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.117952  [   64/60000]\n",
      "loss: 0.143804  [ 6464/60000]\n",
      "loss: 0.171468  [12864/60000]\n",
      "loss: 0.132781  [19264/60000]\n",
      "loss: 0.303117  [25664/60000]\n",
      "loss: 0.226374  [32064/60000]\n",
      "loss: 0.165133  [38464/60000]\n",
      "loss: 0.229570  [44864/60000]\n",
      "loss: 0.194307  [51264/60000]\n",
      "loss: 0.223545  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.384517 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.116424  [   64/60000]\n",
      "loss: 0.184845  [ 6464/60000]\n",
      "loss: 0.129399  [12864/60000]\n",
      "loss: 0.123533  [19264/60000]\n",
      "loss: 0.221683  [25664/60000]\n",
      "loss: 0.190467  [32064/60000]\n",
      "loss: 0.211879  [38464/60000]\n",
      "loss: 0.228477  [44864/60000]\n",
      "loss: 0.153745  [51264/60000]\n",
      "loss: 0.232126  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.391903 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.090314  [   64/60000]\n",
      "loss: 0.128335  [ 6464/60000]\n",
      "loss: 0.141976  [12864/60000]\n",
      "loss: 0.126144  [19264/60000]\n",
      "loss: 0.228877  [25664/60000]\n",
      "loss: 0.208667  [32064/60000]\n",
      "loss: 0.207556  [38464/60000]\n",
      "loss: 0.183167  [44864/60000]\n",
      "loss: 0.151244  [51264/60000]\n",
      "loss: 0.219927  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.412602 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.122623  [   64/60000]\n",
      "loss: 0.138248  [ 6464/60000]\n",
      "loss: 0.189533  [12864/60000]\n",
      "loss: 0.156994  [19264/60000]\n",
      "loss: 0.169571  [25664/60000]\n",
      "loss: 0.210305  [32064/60000]\n",
      "loss: 0.155588  [38464/60000]\n",
      "loss: 0.200987  [44864/60000]\n",
      "loss: 0.153399  [51264/60000]\n",
      "loss: 0.173077  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.407236 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.084088  [   64/60000]\n",
      "loss: 0.104127  [ 6464/60000]\n",
      "loss: 0.148979  [12864/60000]\n",
      "loss: 0.136871  [19264/60000]\n",
      "loss: 0.142690  [25664/60000]\n",
      "loss: 0.208876  [32064/60000]\n",
      "loss: 0.135716  [38464/60000]\n",
      "loss: 0.228391  [44864/60000]\n",
      "loss: 0.111659  [51264/60000]\n",
      "loss: 0.216238  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.396786 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.078532  [   64/60000]\n",
      "loss: 0.100793  [ 6464/60000]\n",
      "loss: 0.175900  [12864/60000]\n",
      "loss: 0.109128  [19264/60000]\n",
      "loss: 0.135680  [25664/60000]\n",
      "loss: 0.203359  [32064/60000]\n",
      "loss: 0.168609  [38464/60000]\n",
      "loss: 0.202701  [44864/60000]\n",
      "loss: 0.108897  [51264/60000]\n",
      "loss: 0.150959  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.461141 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.090038  [   64/60000]\n",
      "loss: 0.134584  [ 6464/60000]\n",
      "loss: 0.150803  [12864/60000]\n",
      "loss: 0.188367  [19264/60000]\n",
      "loss: 0.144817  [25664/60000]\n",
      "loss: 0.189819  [32064/60000]\n",
      "loss: 0.162173  [38464/60000]\n",
      "loss: 0.226901  [44864/60000]\n",
      "loss: 0.134609  [51264/60000]\n",
      "loss: 0.161029  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.434154 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.086886  [   64/60000]\n",
      "loss: 0.108038  [ 6464/60000]\n",
      "loss: 0.212939  [12864/60000]\n",
      "loss: 0.101500  [19264/60000]\n",
      "loss: 0.131301  [25664/60000]\n",
      "loss: 0.204401  [32064/60000]\n",
      "loss: 0.095549  [38464/60000]\n",
      "loss: 0.222411  [44864/60000]\n",
      "loss: 0.118369  [51264/60000]\n",
      "loss: 0.149984  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.483054 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.063439  [   64/60000]\n",
      "loss: 0.090168  [ 6464/60000]\n",
      "loss: 0.231187  [12864/60000]\n",
      "loss: 0.085672  [19264/60000]\n",
      "loss: 0.252054  [25664/60000]\n",
      "loss: 0.187883  [32064/60000]\n",
      "loss: 0.127384  [38464/60000]\n",
      "loss: 0.278278  [44864/60000]\n",
      "loss: 0.110126  [51264/60000]\n",
      "loss: 0.150061  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.447904 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.088509  [   64/60000]\n",
      "loss: 0.160501  [ 6464/60000]\n",
      "loss: 0.190593  [12864/60000]\n",
      "loss: 0.129906  [19264/60000]\n",
      "loss: 0.136956  [25664/60000]\n",
      "loss: 0.181498  [32064/60000]\n",
      "loss: 0.092254  [38464/60000]\n",
      "loss: 0.211387  [44864/60000]\n",
      "loss: 0.061018  [51264/60000]\n",
      "loss: 0.146504  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.489922 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Evaluate ReLU network\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(fcnet.parameters())\n",
    "epochs = 10\n",
    "\n",
    "results = eval(train_dataloader, test_dataloader, fcnet, loss_fn, optimizer, epochs)\n",
    "results.to_csv('results/fcnet_relu.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.308833  [   64/60000]\n",
      "loss: 0.596282  [ 6464/60000]\n",
      "loss: 0.379886  [12864/60000]\n",
      "loss: 0.561692  [19264/60000]\n",
      "loss: 0.463238  [25664/60000]\n",
      "loss: 0.416341  [32064/60000]\n",
      "loss: 0.385961  [38464/60000]\n",
      "loss: 0.508026  [44864/60000]\n",
      "loss: 0.492627  [51264/60000]\n",
      "loss: 0.487733  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.415579 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.286252  [   64/60000]\n",
      "loss: 0.339467  [ 6464/60000]\n",
      "loss: 0.283954  [12864/60000]\n",
      "loss: 0.379861  [19264/60000]\n",
      "loss: 0.414202  [25664/60000]\n",
      "loss: 0.345941  [32064/60000]\n",
      "loss: 0.296767  [38464/60000]\n",
      "loss: 0.435048  [44864/60000]\n",
      "loss: 0.410662  [51264/60000]\n",
      "loss: 0.410783  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.375773 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.206058  [   64/60000]\n",
      "loss: 0.291727  [ 6464/60000]\n",
      "loss: 0.251315  [12864/60000]\n",
      "loss: 0.298110  [19264/60000]\n",
      "loss: 0.362192  [25664/60000]\n",
      "loss: 0.335226  [32064/60000]\n",
      "loss: 0.249108  [38464/60000]\n",
      "loss: 0.374866  [44864/60000]\n",
      "loss: 0.378698  [51264/60000]\n",
      "loss: 0.347185  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.366765 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.178983  [   64/60000]\n",
      "loss: 0.269562  [ 6464/60000]\n",
      "loss: 0.242588  [12864/60000]\n",
      "loss: 0.237471  [19264/60000]\n",
      "loss: 0.382461  [25664/60000]\n",
      "loss: 0.323407  [32064/60000]\n",
      "loss: 0.225910  [38464/60000]\n",
      "loss: 0.307788  [44864/60000]\n",
      "loss: 0.317396  [51264/60000]\n",
      "loss: 0.351447  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.367378 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.193211  [   64/60000]\n",
      "loss: 0.215323  [ 6464/60000]\n",
      "loss: 0.246834  [12864/60000]\n",
      "loss: 0.193040  [19264/60000]\n",
      "loss: 0.371507  [25664/60000]\n",
      "loss: 0.293353  [32064/60000]\n",
      "loss: 0.196893  [38464/60000]\n",
      "loss: 0.290325  [44864/60000]\n",
      "loss: 0.266008  [51264/60000]\n",
      "loss: 0.344239  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.360710 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.149503  [   64/60000]\n",
      "loss: 0.190813  [ 6464/60000]\n",
      "loss: 0.243154  [12864/60000]\n",
      "loss: 0.189507  [19264/60000]\n",
      "loss: 0.372352  [25664/60000]\n",
      "loss: 0.260000  [32064/60000]\n",
      "loss: 0.174302  [38464/60000]\n",
      "loss: 0.288173  [44864/60000]\n",
      "loss: 0.226378  [51264/60000]\n",
      "loss: 0.301501  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.369381 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.141215  [   64/60000]\n",
      "loss: 0.169501  [ 6464/60000]\n",
      "loss: 0.238480  [12864/60000]\n",
      "loss: 0.176775  [19264/60000]\n",
      "loss: 0.308752  [25664/60000]\n",
      "loss: 0.215974  [32064/60000]\n",
      "loss: 0.167591  [38464/60000]\n",
      "loss: 0.245795  [44864/60000]\n",
      "loss: 0.229102  [51264/60000]\n",
      "loss: 0.310132  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.386880 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.159233  [   64/60000]\n",
      "loss: 0.143522  [ 6464/60000]\n",
      "loss: 0.188349  [12864/60000]\n",
      "loss: 0.154798  [19264/60000]\n",
      "loss: 0.227367  [25664/60000]\n",
      "loss: 0.202378  [32064/60000]\n",
      "loss: 0.160930  [38464/60000]\n",
      "loss: 0.272244  [44864/60000]\n",
      "loss: 0.154927  [51264/60000]\n",
      "loss: 0.221682  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.365338 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.157254  [   64/60000]\n",
      "loss: 0.109336  [ 6464/60000]\n",
      "loss: 0.179323  [12864/60000]\n",
      "loss: 0.181133  [19264/60000]\n",
      "loss: 0.178292  [25664/60000]\n",
      "loss: 0.213614  [32064/60000]\n",
      "loss: 0.149811  [38464/60000]\n",
      "loss: 0.265909  [44864/60000]\n",
      "loss: 0.127348  [51264/60000]\n",
      "loss: 0.206039  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.405082 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.138379  [   64/60000]\n",
      "loss: 0.138343  [ 6464/60000]\n",
      "loss: 0.168358  [12864/60000]\n",
      "loss: 0.119195  [19264/60000]\n",
      "loss: 0.312172  [25664/60000]\n",
      "loss: 0.202323  [32064/60000]\n",
      "loss: 0.180256  [38464/60000]\n",
      "loss: 0.210928  [44864/60000]\n",
      "loss: 0.093175  [51264/60000]\n",
      "loss: 0.208735  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.432569 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Evaluate SiLU network\n",
    "optimizer = torch.optim.Adam(silunet.parameters())\n",
    "\n",
    "results = eval(train_dataloader, test_dataloader, silunet, loss_fn, optimizer, epochs)\n",
    "results.to_csv('results/fcnet_silu.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ResNet on CIFAR10 and CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet 164 implementation, adapted from https://github.com/a-martyn/resnet/blob/master/resnet.py\n",
    "\n",
    "class block(nn.Module):\n",
    "    def __init__(self, activation, filters, subsample=False):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        A 2-layer residual learning building block as illustrated by Fig.2\n",
    "        in \"Deep Residual Learning for Image Recognition\"\n",
    "        \n",
    "        Parameters:\n",
    "        \n",
    "        - filters:   int\n",
    "                     the number of filters for all layers in this block\n",
    "                   \n",
    "        - subsample: boolean\n",
    "                     whether to subsample the input feature maps with stride 2\n",
    "                     and doubling in number of filters\n",
    "                     \n",
    "        Attributes:\n",
    "        \n",
    "        - shortcuts: boolean\n",
    "                     When false the residual shortcut is removed\n",
    "                     resulting in a 'plain' convolutional block.\n",
    "        \"\"\"\n",
    "        # Determine subsampling\n",
    "        s = 0.5 if subsample else 1.0\n",
    "        \n",
    "        # Setup layers\n",
    "        self.conv1 = nn.Conv2d(int(filters*s), filters, kernel_size=3, \n",
    "                               stride=int(1/s), padding=1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(filters, track_running_stats=True)\n",
    "        self.activation = activation()\n",
    "        self.conv2 = nn.Conv2d(filters, filters, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm2d(filters, track_running_stats=True)\n",
    "\n",
    "        # Shortcut downsampling\n",
    "        self.downsample = nn.AvgPool2d(kernel_size=1, stride=2)\n",
    "\n",
    "        # Initialise weights according to the method described in \n",
    "        # “Delving deep into rectifiers: Surpassing human-level performance on ImageNet \n",
    "        # classification” - He, K. et al. (2015)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)   \n",
    "        \n",
    "    def shortcut(self, z, x):\n",
    "        \"\"\" \n",
    "        Implements parameter free shortcut connection by identity mapping.\n",
    "        If dimensions of input x are greater than activations then this\n",
    "        is rectified by downsampling and then zero padding dimension 1\n",
    "        as described by option A in paper.\n",
    "        \n",
    "        Parameters:\n",
    "        - x: tensor\n",
    "             the input to the block\n",
    "        - z: tensor\n",
    "             activations of block prior to final non-linearity\n",
    "        \"\"\"\n",
    "        if x.shape != z.shape:\n",
    "            d = self.downsample(x)\n",
    "            p = torch.mul(d, 0)\n",
    "            return z + torch.cat((d, p), dim=1)\n",
    "        else:\n",
    "            return z + x        \n",
    "    \n",
    "    def forward(self, x, shortcuts=False):\n",
    "        z = self.conv1(x)\n",
    "        z = self.bn1(z)\n",
    "        z = self.activation(z)\n",
    "        \n",
    "        z = self.conv2(z)\n",
    "        z = self.bn2(z)\n",
    "        \n",
    "        # Shortcut connection\n",
    "        # This if statement is the only difference between\n",
    "        # a convolutional net and a resnet!\n",
    "        if shortcuts:\n",
    "            z = self.shortcut(z, x)\n",
    "\n",
    "        z = self.activation(z)\n",
    "        \n",
    "        return z\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, activation, n, shortcuts=True):\n",
    "        super().__init__()\n",
    "        self.shortcuts = shortcuts\n",
    "        \n",
    "        # Input\n",
    "        self.convIn = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bnIn   = nn.BatchNorm2d(16, track_running_stats=True)\n",
    "        self.activation   = activation()\n",
    "        \n",
    "        # Stack1\n",
    "        self.stack1 = nn.ModuleList([block(activation, 16, subsample=False) for _ in range(n)])\n",
    "\n",
    "        # Stack2\n",
    "        self.stack2a = block(activation, 32, subsample=True)\n",
    "        self.stack2b = nn.ModuleList([block(activation, 32, subsample=False) for _ in range(n-1)])\n",
    "\n",
    "        # Stack3\n",
    "        self.stack3a = block(activation, 64, subsample=True)\n",
    "        self.stack3b = nn.ModuleList([block(activation, 64, subsample=False) for _ in range(n-1)])\n",
    "        \n",
    "        # Output\n",
    "        # The parameters of this average pool are not specified in paper.\n",
    "        # Initially I tried kernel_size=2 stride=2 resulting in \n",
    "        # 64*4*4= 1024 inputs to the fully connected layer. More aggresive\n",
    "        # pooling as implemented below results in better results and also\n",
    "        # better matches the total model parameter count cited by authors.\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fcOut   = nn.Linear(64, 10, bias=True)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "        # Initilise weights in fully connected layer \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                m.bias.data.zero_()      \n",
    "        \n",
    "        \n",
    "    def forward(self, x):     \n",
    "        z = self.convIn(x)\n",
    "        z = self.bnIn(z)\n",
    "        z = self.activation(z)\n",
    "        \n",
    "        for l in self.stack1: z = l(z, shortcuts=self.shortcuts)\n",
    "        \n",
    "        z = self.stack2a(z, shortcuts=self.shortcuts)\n",
    "        for l in self.stack2b: \n",
    "            z = l(z, shortcuts=self.shortcuts)\n",
    "        \n",
    "        z = self.stack3a(z, shortcuts=self.shortcuts)\n",
    "        for l in self.stack3b: \n",
    "            z = l(z, shortcuts=self.shortcuts)\n",
    "\n",
    "        z = self.avgpool(z)\n",
    "        z = z.view(z.size(0), -1)\n",
    "        z = self.fcOut(z)\n",
    "        return self.softmax(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training and test data from PyTorch open datasets and create dataloaders\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Do not transform test data\n",
    "test_transform = transforms.ToTensor()\n",
    "\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make classes for functions not available in library\n",
    "class MaxXSigmoid(nn.Module):\n",
    "    __constants__ = ['inplace']\n",
    "    inplace: bool\n",
    "\n",
    "    def __init__(self, inplace: bool = False):\n",
    "        super().__init__()\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.max(input, nn.Sigmoid(input))\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        inplace_str = 'inplace=True' if self.inplace else ''\n",
    "        return inplace_str\n",
    "\n",
    "class CosxMinusX(nn.Module):\n",
    "    __constants__ = ['inplace']\n",
    "    inplace: bool\n",
    "\n",
    "    def __init__(self, inplace: bool = False):\n",
    "        super().__init__()\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.cos(input) - input\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        inplace_str = 'inplace=True' if self.inplace else ''\n",
    "        return inplace_str\n",
    "\n",
    "# Map function names to functions\n",
    "functions = {\n",
    "    'relu' : nn.ReLU,\n",
    "    'silu' : nn.SiLU,\n",
    "    'max_x_sigmoid' : MaxXSigmoid,\n",
    "    'cosx_minus_x' : CosxMinusX,\n",
    "    'lrelu' : nn.LeakyReLU,\n",
    "    'prelu' : nn.PReLU,\n",
    "    'softplus' : nn.Softplus\n",
    "}\n",
    "\n",
    "# Specify ResNet model sizes. Size parameter n will create a 6n+2 layer model.\n",
    "model_sizes = [3, 5, 7, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 20 layer model with activation function: relu\n",
      "Results already generated, skipping\n",
      "Evaluating 20 layer model with activation function: silu\n",
      "Results already generated, skipping\n",
      "Evaluating 20 layer model with activation function: max_x_sigmoid\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Done in 497.36021783299657 secs, saved to results/resnet_20_max_x_sigmoid.csv\n",
      "Evaluating 20 layer model with activation function: cosx_minus_x\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Done in 405.4669588329998 secs, saved to results/resnet_20_cosx_minus_x.csv\n",
      "Evaluating 20 layer model with activation function: lrelu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Done in 359.71302404200105 secs, saved to results/resnet_20_lrelu.csv\n",
      "Evaluating 20 layer model with activation function: prelu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Done in 406.3345300000001 secs, saved to results/resnet_20_prelu.csv\n",
      "Evaluating 20 layer model with activation function: softplus\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Done in 365.76617850000184 secs, saved to results/resnet_20_softplus.csv\n",
      "Evaluating 32 layer model with activation function: relu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Done in 541.6648986670043 secs, saved to results/resnet_32_relu.csv\n",
      "Evaluating 32 layer model with activation function: silu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Done in 533.0018880839998 secs, saved to results/resnet_32_silu.csv\n",
      "Evaluating 32 layer model with activation function: max_x_sigmoid\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Done in 717.4761454999971 secs, saved to results/resnet_32_max_x_sigmoid.csv\n",
      "Evaluating 32 layer model with activation function: cosx_minus_x\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Done in 618.640773666004 secs, saved to results/resnet_32_cosx_minus_x.csv\n",
      "Evaluating 32 layer model with activation function: lrelu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Done in 540.5402703750005 secs, saved to results/resnet_32_lrelu.csv\n",
      "Evaluating 32 layer model with activation function: prelu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Done in 608.2152554580025 secs, saved to results/resnet_32_prelu.csv\n",
      "Evaluating 32 layer model with activation function: softplus\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Done in 547.025621834 secs, saved to results/resnet_32_softplus.csv\n",
      "Evaluating 44 layer model with activation function: relu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Done in 718.2529850410065 secs, saved to results/resnet_44_relu.csv\n",
      "Evaluating 44 layer model with activation function: silu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Done in 712.8263072920017 secs, saved to results/resnet_44_silu.csv\n",
      "Evaluating 44 layer model with activation function: max_x_sigmoid\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Done in 985.1205608339951 secs, saved to results/resnet_44_max_x_sigmoid.csv\n",
      "Evaluating 44 layer model with activation function: cosx_minus_x\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Done in 833.1031650829973 secs, saved to results/resnet_44_cosx_minus_x.csv\n",
      "Evaluating 44 layer model with activation function: lrelu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Done in 721.6251503750027 secs, saved to results/resnet_44_lrelu.csv\n",
      "Evaluating 44 layer model with activation function: prelu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Done in 827.9036749170045 secs, saved to results/resnet_44_prelu.csv\n",
      "Evaluating 44 layer model with activation function: softplus\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Done in 734.3536161250013 secs, saved to results/resnet_44_softplus.csv\n",
      "Evaluating 56 layer model with activation function: relu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Done in 885.5212895000004 secs, saved to results/resnet_56_relu.csv\n",
      "Evaluating 56 layer model with activation function: silu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Done in 874.195700915996 secs, saved to results/resnet_56_silu.csv\n",
      "Evaluating 56 layer model with activation function: max_x_sigmoid\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Done in 1157.8973690830026 secs, saved to results/resnet_56_max_x_sigmoid.csv\n",
      "Evaluating 56 layer model with activation function: cosx_minus_x\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Done in 974.9572687919936 secs, saved to results/resnet_56_cosx_minus_x.csv\n",
      "Evaluating 56 layer model with activation function: lrelu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Done in 849.8355208339999 secs, saved to results/resnet_56_lrelu.csv\n",
      "Evaluating 56 layer model with activation function: prelu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Done in 992.3846608340027 secs, saved to results/resnet_56_prelu.csv\n",
      "Evaluating 56 layer model with activation function: softplus\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Done in 889.8994272499986 secs, saved to results/resnet_56_softplus.csv\n"
     ]
    }
   ],
   "source": [
    "for n in model_sizes:\n",
    "    for funcname, function in functions.items():\n",
    "        save_to = f'results/resnet_{6*n+2}_{funcname}.csv'\n",
    "        print(f'Evaluating {6*n+2} layer model with activation function: {funcname}')\n",
    "        if os.path.isfile(save_to):\n",
    "            print(f'Results already generated, skipping')\n",
    "        else:\n",
    "            training_data = datasets.CIFAR10(\n",
    "                root=\"data\",\n",
    "                train=True,\n",
    "                download=True,\n",
    "                transform=train_transform\n",
    "            )\n",
    "\n",
    "            test_data = datasets.CIFAR10(\n",
    "                root=\"data\",\n",
    "                train=False,\n",
    "                download=True,\n",
    "                transform=test_transform\n",
    "            )\n",
    "            train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "            test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "            model = ResNet(function, n).to(device)\n",
    "            loss_fn = torch.nn.CrossEntropyLoss()\n",
    "            optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "            start = time.perf_counter()\n",
    "            results = eval(train_dataloader, test_dataloader, model, loss_fn, optimizer, epochs, quiet=True)\n",
    "            end = time.perf_counter()\n",
    "            dur = end - start\n",
    "            times[f'resnet_{6*n+2}_{funcname}'] = dur\n",
    "            results.to_csv(save_to)\n",
    "            print(f'Done in {dur} secs, saved to {save_to}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
