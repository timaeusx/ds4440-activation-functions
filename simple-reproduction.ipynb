{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install torch\n",
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "# Configure hardware\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train, test, evaluation functions\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            losses.append(loss)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    return np.mean(losses)\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return correct, test_loss\n",
    "\n",
    "def eval(train_dataloader, test_dataloader, model, loss_fn, optimizer, epochs):\n",
    "    overall_train_loss = []\n",
    "    overall_test_acc = []\n",
    "    overall_test_loss = []\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_loss = train(train_dataloader, model, loss_fn, optimizer)\n",
    "        test_acc, test_loss = test(test_dataloader, model, loss_fn)\n",
    "        overall_train_loss.append(train_loss)\n",
    "        overall_test_acc.append(test_acc)\n",
    "        overall_test_loss.append(test_loss)\n",
    "        print(\"Done!\")\n",
    "    return pd.DataFrame({\n",
    "        'train loss' : overall_train_loss, \n",
    "        'test_acc' : overall_test_acc, \n",
    "        'test_loss' : overall_test_loss\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fully Connected Network Classifier on Fashion MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCNet(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (sequential): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "FCNet(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (sequential): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): SiLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): SiLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Fully connected network with variable activation function\n",
    "class FCNet(nn.Module):\n",
    "    def __init__(self, activation):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            activation(),\n",
    "            nn.Linear(512, 512),\n",
    "            activation(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.sequential(x)\n",
    "        return logits\n",
    "\n",
    "fcnet = FCNet(nn.ReLU).to(device)\n",
    "silunet = FCNet(nn.SiLU).to(device)\n",
    "\n",
    "print(fcnet)\n",
    "print(silunet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Download training and test data from PyTorch open datasets and create dataloaders\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.117952  [   64/60000]\n",
      "loss: 0.143804  [ 6464/60000]\n",
      "loss: 0.171468  [12864/60000]\n",
      "loss: 0.132781  [19264/60000]\n",
      "loss: 0.303117  [25664/60000]\n",
      "loss: 0.226374  [32064/60000]\n",
      "loss: 0.165133  [38464/60000]\n",
      "loss: 0.229570  [44864/60000]\n",
      "loss: 0.194307  [51264/60000]\n",
      "loss: 0.223545  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.384517 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.116424  [   64/60000]\n",
      "loss: 0.184845  [ 6464/60000]\n",
      "loss: 0.129399  [12864/60000]\n",
      "loss: 0.123533  [19264/60000]\n",
      "loss: 0.221683  [25664/60000]\n",
      "loss: 0.190467  [32064/60000]\n",
      "loss: 0.211879  [38464/60000]\n",
      "loss: 0.228477  [44864/60000]\n",
      "loss: 0.153745  [51264/60000]\n",
      "loss: 0.232126  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.391903 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.090314  [   64/60000]\n",
      "loss: 0.128335  [ 6464/60000]\n",
      "loss: 0.141976  [12864/60000]\n",
      "loss: 0.126144  [19264/60000]\n",
      "loss: 0.228877  [25664/60000]\n",
      "loss: 0.208667  [32064/60000]\n",
      "loss: 0.207556  [38464/60000]\n",
      "loss: 0.183167  [44864/60000]\n",
      "loss: 0.151244  [51264/60000]\n",
      "loss: 0.219927  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.412602 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.122623  [   64/60000]\n",
      "loss: 0.138248  [ 6464/60000]\n",
      "loss: 0.189533  [12864/60000]\n",
      "loss: 0.156994  [19264/60000]\n",
      "loss: 0.169571  [25664/60000]\n",
      "loss: 0.210305  [32064/60000]\n",
      "loss: 0.155588  [38464/60000]\n",
      "loss: 0.200987  [44864/60000]\n",
      "loss: 0.153399  [51264/60000]\n",
      "loss: 0.173077  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.407236 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.084088  [   64/60000]\n",
      "loss: 0.104127  [ 6464/60000]\n",
      "loss: 0.148979  [12864/60000]\n",
      "loss: 0.136871  [19264/60000]\n",
      "loss: 0.142690  [25664/60000]\n",
      "loss: 0.208876  [32064/60000]\n",
      "loss: 0.135716  [38464/60000]\n",
      "loss: 0.228391  [44864/60000]\n",
      "loss: 0.111659  [51264/60000]\n",
      "loss: 0.216238  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.396786 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.078532  [   64/60000]\n",
      "loss: 0.100793  [ 6464/60000]\n",
      "loss: 0.175900  [12864/60000]\n",
      "loss: 0.109128  [19264/60000]\n",
      "loss: 0.135680  [25664/60000]\n",
      "loss: 0.203359  [32064/60000]\n",
      "loss: 0.168609  [38464/60000]\n",
      "loss: 0.202701  [44864/60000]\n",
      "loss: 0.108897  [51264/60000]\n",
      "loss: 0.150959  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.461141 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.090038  [   64/60000]\n",
      "loss: 0.134584  [ 6464/60000]\n",
      "loss: 0.150803  [12864/60000]\n",
      "loss: 0.188367  [19264/60000]\n",
      "loss: 0.144817  [25664/60000]\n",
      "loss: 0.189819  [32064/60000]\n",
      "loss: 0.162173  [38464/60000]\n",
      "loss: 0.226901  [44864/60000]\n",
      "loss: 0.134609  [51264/60000]\n",
      "loss: 0.161029  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.434154 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.086886  [   64/60000]\n",
      "loss: 0.108038  [ 6464/60000]\n",
      "loss: 0.212939  [12864/60000]\n",
      "loss: 0.101500  [19264/60000]\n",
      "loss: 0.131301  [25664/60000]\n",
      "loss: 0.204401  [32064/60000]\n",
      "loss: 0.095549  [38464/60000]\n",
      "loss: 0.222411  [44864/60000]\n",
      "loss: 0.118369  [51264/60000]\n",
      "loss: 0.149984  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.483054 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.063439  [   64/60000]\n",
      "loss: 0.090168  [ 6464/60000]\n",
      "loss: 0.231187  [12864/60000]\n",
      "loss: 0.085672  [19264/60000]\n",
      "loss: 0.252054  [25664/60000]\n",
      "loss: 0.187883  [32064/60000]\n",
      "loss: 0.127384  [38464/60000]\n",
      "loss: 0.278278  [44864/60000]\n",
      "loss: 0.110126  [51264/60000]\n",
      "loss: 0.150061  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.447904 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.088509  [   64/60000]\n",
      "loss: 0.160501  [ 6464/60000]\n",
      "loss: 0.190593  [12864/60000]\n",
      "loss: 0.129906  [19264/60000]\n",
      "loss: 0.136956  [25664/60000]\n",
      "loss: 0.181498  [32064/60000]\n",
      "loss: 0.092254  [38464/60000]\n",
      "loss: 0.211387  [44864/60000]\n",
      "loss: 0.061018  [51264/60000]\n",
      "loss: 0.146504  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.489922 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Evaluate ReLU network\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(fcnet.parameters(), lr=1e-3)\n",
    "epochs = 10\n",
    "\n",
    "results = eval(train_dataloader, test_dataloader, fcnet, loss_fn, optimizer, epochs)\n",
    "results.to_csv('results/fcnet_relu.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.308833  [   64/60000]\n",
      "loss: 0.596282  [ 6464/60000]\n",
      "loss: 0.379886  [12864/60000]\n",
      "loss: 0.561692  [19264/60000]\n",
      "loss: 0.463238  [25664/60000]\n",
      "loss: 0.416341  [32064/60000]\n",
      "loss: 0.385961  [38464/60000]\n",
      "loss: 0.508026  [44864/60000]\n",
      "loss: 0.492627  [51264/60000]\n",
      "loss: 0.487733  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.415579 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.286252  [   64/60000]\n",
      "loss: 0.339467  [ 6464/60000]\n",
      "loss: 0.283954  [12864/60000]\n",
      "loss: 0.379861  [19264/60000]\n",
      "loss: 0.414202  [25664/60000]\n",
      "loss: 0.345941  [32064/60000]\n",
      "loss: 0.296767  [38464/60000]\n",
      "loss: 0.435048  [44864/60000]\n",
      "loss: 0.410662  [51264/60000]\n",
      "loss: 0.410783  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.375773 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.206058  [   64/60000]\n",
      "loss: 0.291727  [ 6464/60000]\n",
      "loss: 0.251315  [12864/60000]\n",
      "loss: 0.298110  [19264/60000]\n",
      "loss: 0.362192  [25664/60000]\n",
      "loss: 0.335226  [32064/60000]\n",
      "loss: 0.249108  [38464/60000]\n",
      "loss: 0.374866  [44864/60000]\n",
      "loss: 0.378698  [51264/60000]\n",
      "loss: 0.347185  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.366765 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.178983  [   64/60000]\n",
      "loss: 0.269562  [ 6464/60000]\n",
      "loss: 0.242588  [12864/60000]\n",
      "loss: 0.237471  [19264/60000]\n",
      "loss: 0.382461  [25664/60000]\n",
      "loss: 0.323407  [32064/60000]\n",
      "loss: 0.225910  [38464/60000]\n",
      "loss: 0.307788  [44864/60000]\n",
      "loss: 0.317396  [51264/60000]\n",
      "loss: 0.351447  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.367378 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.193211  [   64/60000]\n",
      "loss: 0.215323  [ 6464/60000]\n",
      "loss: 0.246834  [12864/60000]\n",
      "loss: 0.193040  [19264/60000]\n",
      "loss: 0.371507  [25664/60000]\n",
      "loss: 0.293353  [32064/60000]\n",
      "loss: 0.196893  [38464/60000]\n",
      "loss: 0.290325  [44864/60000]\n",
      "loss: 0.266008  [51264/60000]\n",
      "loss: 0.344239  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.360710 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.149503  [   64/60000]\n",
      "loss: 0.190813  [ 6464/60000]\n",
      "loss: 0.243154  [12864/60000]\n",
      "loss: 0.189507  [19264/60000]\n",
      "loss: 0.372352  [25664/60000]\n",
      "loss: 0.260000  [32064/60000]\n",
      "loss: 0.174302  [38464/60000]\n",
      "loss: 0.288173  [44864/60000]\n",
      "loss: 0.226378  [51264/60000]\n",
      "loss: 0.301501  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.369381 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.141215  [   64/60000]\n",
      "loss: 0.169501  [ 6464/60000]\n",
      "loss: 0.238480  [12864/60000]\n",
      "loss: 0.176775  [19264/60000]\n",
      "loss: 0.308752  [25664/60000]\n",
      "loss: 0.215974  [32064/60000]\n",
      "loss: 0.167591  [38464/60000]\n",
      "loss: 0.245795  [44864/60000]\n",
      "loss: 0.229102  [51264/60000]\n",
      "loss: 0.310132  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.386880 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.159233  [   64/60000]\n",
      "loss: 0.143522  [ 6464/60000]\n",
      "loss: 0.188349  [12864/60000]\n",
      "loss: 0.154798  [19264/60000]\n",
      "loss: 0.227367  [25664/60000]\n",
      "loss: 0.202378  [32064/60000]\n",
      "loss: 0.160930  [38464/60000]\n",
      "loss: 0.272244  [44864/60000]\n",
      "loss: 0.154927  [51264/60000]\n",
      "loss: 0.221682  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.365338 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.157254  [   64/60000]\n",
      "loss: 0.109336  [ 6464/60000]\n",
      "loss: 0.179323  [12864/60000]\n",
      "loss: 0.181133  [19264/60000]\n",
      "loss: 0.178292  [25664/60000]\n",
      "loss: 0.213614  [32064/60000]\n",
      "loss: 0.149811  [38464/60000]\n",
      "loss: 0.265909  [44864/60000]\n",
      "loss: 0.127348  [51264/60000]\n",
      "loss: 0.206039  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.405082 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.138379  [   64/60000]\n",
      "loss: 0.138343  [ 6464/60000]\n",
      "loss: 0.168358  [12864/60000]\n",
      "loss: 0.119195  [19264/60000]\n",
      "loss: 0.312172  [25664/60000]\n",
      "loss: 0.202323  [32064/60000]\n",
      "loss: 0.180256  [38464/60000]\n",
      "loss: 0.210928  [44864/60000]\n",
      "loss: 0.093175  [51264/60000]\n",
      "loss: 0.208735  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.432569 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Evaluate SiLU network\n",
    "optimizer = torch.optim.Adam(silunet.parameters())\n",
    "\n",
    "results = eval(train_dataloader, test_dataloader, silunet, loss_fn, optimizer, epochs)\n",
    "results.to_csv('results/fcnet_silu.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ResNet on CIFAR10 and CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet 164 implementation, adapted from https://github.com/a-martyn/resnet/blob/master/resnet.py\n",
    "\n",
    "class block(nn.Module):\n",
    "    def __init__(self, activation, filters, subsample=False):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        A 2-layer residual learning building block as illustrated by Fig.2\n",
    "        in \"Deep Residual Learning for Image Recognition\"\n",
    "        \n",
    "        Parameters:\n",
    "        \n",
    "        - filters:   int\n",
    "                     the number of filters for all layers in this block\n",
    "                   \n",
    "        - subsample: boolean\n",
    "                     whether to subsample the input feature maps with stride 2\n",
    "                     and doubling in number of filters\n",
    "                     \n",
    "        Attributes:\n",
    "        \n",
    "        - shortcuts: boolean\n",
    "                     When false the residual shortcut is removed\n",
    "                     resulting in a 'plain' convolutional block.\n",
    "        \"\"\"\n",
    "        # Determine subsampling\n",
    "        s = 0.5 if subsample else 1.0\n",
    "        \n",
    "        # Setup layers\n",
    "        self.conv1 = nn.Conv2d(int(filters*s), filters, kernel_size=3, \n",
    "                               stride=int(1/s), padding=1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(filters, track_running_stats=True)\n",
    "        self.activation = activation()\n",
    "        self.conv2 = nn.Conv2d(filters, filters, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm2d(filters, track_running_stats=True)\n",
    "\n",
    "        # Shortcut downsampling\n",
    "        self.downsample = nn.AvgPool2d(kernel_size=1, stride=2)\n",
    "\n",
    "        # Initialise weights according to the method described in \n",
    "        # “Delving deep into rectifiers: Surpassing human-level performance on ImageNet \n",
    "        # classification” - He, K. et al. (2015)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)   \n",
    "        \n",
    "    def shortcut(self, z, x):\n",
    "        \"\"\" \n",
    "        Implements parameter free shortcut connection by identity mapping.\n",
    "        If dimensions of input x are greater than activations then this\n",
    "        is rectified by downsampling and then zero padding dimension 1\n",
    "        as described by option A in paper.\n",
    "        \n",
    "        Parameters:\n",
    "        - x: tensor\n",
    "             the input to the block\n",
    "        - z: tensor\n",
    "             activations of block prior to final non-linearity\n",
    "        \"\"\"\n",
    "        if x.shape != z.shape:\n",
    "            d = self.downsample(x)\n",
    "            p = torch.mul(d, 0)\n",
    "            return z + torch.cat((d, p), dim=1)\n",
    "        else:\n",
    "            return z + x        \n",
    "    \n",
    "    def forward(self, x, shortcuts=False):\n",
    "        z = self.conv1(x)\n",
    "        z = self.bn1(z)\n",
    "        z = self.activation(z)\n",
    "        \n",
    "        z = self.conv2(z)\n",
    "        z = self.bn2(z)\n",
    "        \n",
    "        # Shortcut connection\n",
    "        # This if statement is the only difference between\n",
    "        # a convolutional net and a resnet!\n",
    "        if shortcuts:\n",
    "            z = self.shortcut(z, x)\n",
    "\n",
    "        z = self.activation(z)\n",
    "        \n",
    "        return z\n",
    "    \n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, activation, n, shortcuts=True):\n",
    "        super().__init__()\n",
    "        self.shortcuts = shortcuts\n",
    "        \n",
    "        # Input\n",
    "        self.convIn = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bnIn   = nn.BatchNorm2d(16, track_running_stats=True)\n",
    "        self.activation   = activation()\n",
    "        \n",
    "        # Stack1\n",
    "        self.stack1 = nn.ModuleList([block(activation, 16, subsample=False) for _ in range(n)])\n",
    "\n",
    "        # Stack2\n",
    "        self.stack2a = block(activation, 32, subsample=True)\n",
    "        self.stack2b = nn.ModuleList([block(activation, 32, subsample=False) for _ in range(n-1)])\n",
    "\n",
    "        # Stack3\n",
    "        self.stack3a = block(activation, 64, subsample=True)\n",
    "        self.stack3b = nn.ModuleList([block(activation, 64, subsample=False) for _ in range(n-1)])\n",
    "        \n",
    "        # Output\n",
    "        # The parameters of this average pool are not specified in paper.\n",
    "        # Initially I tried kernel_size=2 stride=2 resulting in \n",
    "        # 64*4*4= 1024 inputs to the fully connected layer. More aggresive\n",
    "        # pooling as implemented below results in better results and also\n",
    "        # better matches the total model parameter count cited by authors.\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fcOut   = nn.Linear(64, 10, bias=True)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "        # Initilise weights in fully connected layer \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                m.bias.data.zero_()      \n",
    "        \n",
    "        \n",
    "    def forward(self, x):     \n",
    "        z = self.convIn(x)\n",
    "        z = self.bnIn(z)\n",
    "        z = self.activation(z)\n",
    "        \n",
    "        for l in self.stack1: z = l(z, shortcuts=self.shortcuts)\n",
    "        \n",
    "        z = self.stack2a(z, shortcuts=self.shortcuts)\n",
    "        for l in self.stack2b: \n",
    "            z = l(z, shortcuts=self.shortcuts)\n",
    "        \n",
    "        z = self.stack3a(z, shortcuts=self.shortcuts)\n",
    "        for l in self.stack3b: \n",
    "            z = l(z, shortcuts=self.shortcuts)\n",
    "\n",
    "        z = self.avgpool(z)\n",
    "        z = z.view(z.size(0), -1)\n",
    "        z = self.fcOut(z)\n",
    "        return self.softmax(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 3, 32, 32])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Download training and test data from PyTorch open datasets and create dataloaders\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "training_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "test_transform = transforms.ToTensor()\n",
    "\n",
    "\n",
    "test_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q4/f1bk43fj16d9fzyx007gcx_c0000gp/T/ipykernel_94278/810095406.py:123: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight)\n"
     ]
    }
   ],
   "source": [
    "resnet_relu = ResNet(nn.ReLU, 3).to(device)\n",
    "resnet_silu = ResNet(nn.SiLU, 3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.755440  [   64/50000]\n",
      "loss: 1.586624  [ 6464/50000]\n",
      "loss: 1.262855  [12864/50000]\n",
      "loss: 1.403428  [19264/50000]\n",
      "loss: 1.402931  [25664/50000]\n",
      "loss: 1.450590  [32064/50000]\n",
      "loss: 1.366369  [38464/50000]\n",
      "loss: 1.283585  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 1.232394 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.190705  [   64/50000]\n",
      "loss: 1.117294  [ 6464/50000]\n",
      "loss: 0.969083  [12864/50000]\n",
      "loss: 1.103904  [19264/50000]\n",
      "loss: 1.104823  [25664/50000]\n",
      "loss: 1.336930  [32064/50000]\n",
      "loss: 1.065357  [38464/50000]\n",
      "loss: 1.095886  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 65.6%, Avg loss: 0.993317 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.903309  [   64/50000]\n",
      "loss: 0.936006  [ 6464/50000]\n",
      "loss: 0.724649  [12864/50000]\n",
      "loss: 0.843482  [19264/50000]\n",
      "loss: 0.965253  [25664/50000]\n",
      "loss: 1.189905  [32064/50000]\n",
      "loss: 0.865692  [38464/50000]\n",
      "loss: 0.889967  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 67.2%, Avg loss: 0.965365 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.851643  [   64/50000]\n",
      "loss: 0.892428  [ 6464/50000]\n",
      "loss: 0.582652  [12864/50000]\n",
      "loss: 0.760422  [19264/50000]\n",
      "loss: 0.927889  [25664/50000]\n",
      "loss: 1.021355  [32064/50000]\n",
      "loss: 0.752236  [38464/50000]\n",
      "loss: 0.796045  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 0.770829 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.737546  [   64/50000]\n",
      "loss: 0.678386  [ 6464/50000]\n",
      "loss: 0.620788  [12864/50000]\n",
      "loss: 0.648923  [19264/50000]\n",
      "loss: 0.921389  [25664/50000]\n",
      "loss: 0.961856  [32064/50000]\n",
      "loss: 0.678064  [38464/50000]\n",
      "loss: 0.730810  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.764382 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.573373  [   64/50000]\n",
      "loss: 0.661220  [ 6464/50000]\n",
      "loss: 0.554462  [12864/50000]\n",
      "loss: 0.700744  [19264/50000]\n",
      "loss: 0.698100  [25664/50000]\n",
      "loss: 0.921426  [32064/50000]\n",
      "loss: 0.574869  [38464/50000]\n",
      "loss: 0.660490  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 0.837876 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.519850  [   64/50000]\n",
      "loss: 0.641895  [ 6464/50000]\n",
      "loss: 0.490701  [12864/50000]\n",
      "loss: 0.651439  [19264/50000]\n",
      "loss: 0.716817  [25664/50000]\n",
      "loss: 0.907937  [32064/50000]\n",
      "loss: 0.557762  [38464/50000]\n",
      "loss: 0.620341  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.612216 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.517686  [   64/50000]\n",
      "loss: 0.502554  [ 6464/50000]\n",
      "loss: 0.389622  [12864/50000]\n",
      "loss: 0.580877  [19264/50000]\n",
      "loss: 0.615105  [25664/50000]\n",
      "loss: 0.857745  [32064/50000]\n",
      "loss: 0.608478  [38464/50000]\n",
      "loss: 0.572339  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.652966 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.336309  [   64/50000]\n",
      "loss: 0.477717  [ 6464/50000]\n",
      "loss: 0.350273  [12864/50000]\n",
      "loss: 0.580656  [19264/50000]\n",
      "loss: 0.576205  [25664/50000]\n",
      "loss: 0.808194  [32064/50000]\n",
      "loss: 0.496729  [38464/50000]\n",
      "loss: 0.660686  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.574829 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.358046  [   64/50000]\n",
      "loss: 0.537099  [ 6464/50000]\n",
      "loss: 0.339792  [12864/50000]\n",
      "loss: 0.520085  [19264/50000]\n",
      "loss: 0.663712  [25664/50000]\n",
      "loss: 0.806937  [32064/50000]\n",
      "loss: 0.453824  [38464/50000]\n",
      "loss: 0.515322  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.585286 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(resnet_relu.parameters())\n",
    "\n",
    "results = eval(train_dataloader, test_dataloader, resnet_relu, loss_fn, optimizer, epochs)\n",
    "results.to_csv('resnet_relu_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.889300  [   64/50000]\n",
      "loss: 1.614534  [ 6464/50000]\n",
      "loss: 1.318044  [12864/50000]\n",
      "loss: 1.403661  [19264/50000]\n",
      "loss: 1.437201  [25664/50000]\n",
      "loss: 1.346170  [32064/50000]\n",
      "loss: 1.205990  [38464/50000]\n",
      "loss: 1.208679  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 61.0%, Avg loss: 1.108664 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.076397  [   64/50000]\n",
      "loss: 1.109718  [ 6464/50000]\n",
      "loss: 0.923419  [12864/50000]\n",
      "loss: 1.063451  [19264/50000]\n",
      "loss: 1.149035  [25664/50000]\n",
      "loss: 1.212288  [32064/50000]\n",
      "loss: 0.910367  [38464/50000]\n",
      "loss: 1.097296  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 0.857176 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.900486  [   64/50000]\n",
      "loss: 0.927178  [ 6464/50000]\n",
      "loss: 0.690153  [12864/50000]\n",
      "loss: 0.882510  [19264/50000]\n",
      "loss: 0.937455  [25664/50000]\n",
      "loss: 1.196976  [32064/50000]\n",
      "loss: 0.840949  [38464/50000]\n",
      "loss: 0.861300  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 0.827903 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.778923  [   64/50000]\n",
      "loss: 0.826030  [ 6464/50000]\n",
      "loss: 0.631650  [12864/50000]\n",
      "loss: 0.626223  [19264/50000]\n",
      "loss: 0.696192  [25664/50000]\n",
      "loss: 1.053012  [32064/50000]\n",
      "loss: 0.649905  [38464/50000]\n",
      "loss: 0.790387  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.675738 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.641758  [   64/50000]\n",
      "loss: 0.772757  [ 6464/50000]\n",
      "loss: 0.508992  [12864/50000]\n",
      "loss: 0.744901  [19264/50000]\n",
      "loss: 0.735947  [25664/50000]\n",
      "loss: 0.900663  [32064/50000]\n",
      "loss: 0.710589  [38464/50000]\n",
      "loss: 0.786205  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.695914 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.633159  [   64/50000]\n",
      "loss: 0.616066  [ 6464/50000]\n",
      "loss: 0.483242  [12864/50000]\n",
      "loss: 0.798694  [19264/50000]\n",
      "loss: 0.703300  [25664/50000]\n",
      "loss: 0.824276  [32064/50000]\n",
      "loss: 0.576992  [38464/50000]\n",
      "loss: 0.777086  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.650515 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.529721  [   64/50000]\n",
      "loss: 0.544423  [ 6464/50000]\n",
      "loss: 0.453094  [12864/50000]\n",
      "loss: 0.661698  [19264/50000]\n",
      "loss: 0.565413  [25664/50000]\n",
      "loss: 0.697061  [32064/50000]\n",
      "loss: 0.565905  [38464/50000]\n",
      "loss: 0.732816  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.618471 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.496973  [   64/50000]\n",
      "loss: 0.555560  [ 6464/50000]\n",
      "loss: 0.485004  [12864/50000]\n",
      "loss: 0.563059  [19264/50000]\n",
      "loss: 0.590251  [25664/50000]\n",
      "loss: 0.760553  [32064/50000]\n",
      "loss: 0.560456  [38464/50000]\n",
      "loss: 0.664943  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.544020 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.501579  [   64/50000]\n",
      "loss: 0.494965  [ 6464/50000]\n",
      "loss: 0.409019  [12864/50000]\n",
      "loss: 0.670848  [19264/50000]\n",
      "loss: 0.587484  [25664/50000]\n",
      "loss: 0.575532  [32064/50000]\n",
      "loss: 0.415442  [38464/50000]\n",
      "loss: 0.731993  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.530285 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.425136  [   64/50000]\n",
      "loss: 0.477048  [ 6464/50000]\n",
      "loss: 0.351916  [12864/50000]\n",
      "loss: 0.450208  [19264/50000]\n",
      "loss: 0.454270  [25664/50000]\n",
      "loss: 0.622011  [32064/50000]\n",
      "loss: 0.386205  [38464/50000]\n",
      "loss: 0.614386  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.554090 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(resnet_silu.parameters())\n",
    "\n",
    "results = eval(train_dataloader, test_dataloader, resnet_silu, loss_fn, optimizer, epochs)\n",
    "results.to_csv('resnet_silu_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make classes for functions not available in library\n",
    "class MaxXSigmoid(nn.Module):\n",
    "    __constants__ = ['inplace']\n",
    "    inplace: bool\n",
    "\n",
    "    def __init__(self, inplace: bool = False):\n",
    "        super().__init__()\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.max(input, nn.Sigmoid(input, inplace=self.inplace))\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        inplace_str = 'inplace=True' if self.inplace else ''\n",
    "        return inplace_str\n",
    "\n",
    "class CosxMinusX(nn.Module):\n",
    "    __constants__ = ['inplace']\n",
    "    inplace: bool\n",
    "\n",
    "    def __init__(self, inplace: bool = False):\n",
    "        super().__init__()\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.cos(input) - input\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        inplace_str = 'inplace=True' if self.inplace else ''\n",
    "        return inplace_str\n",
    "\n",
    "# Map function names to functions\n",
    "functions = {\n",
    "    'relu' : nn.ReLU,\n",
    "    'silu' : nn.SiLU,\n",
    "    'max_x_sigmoid' : MaxXSigmoid,\n",
    "    'cosx_minus_x' : CosxMinusX,\n",
    "    'lrelu' : nn.LeakyReLU,\n",
    "    'prelu' : nn.PReLU,\n",
    "    'softplus' : nn.Softplus\n",
    "}\n",
    "\n",
    "# Specify ResNet model sizes. Size parameter n will create a 6n+2 layer model.\n",
    "model_sizes = [3, 5, 7, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 20 layer model with activation function: relu\n",
      "Results already generated, skipping\n",
      "Evaluating 20 layer model with activation function: silu\n",
      "Results already generated, skipping\n",
      "Evaluating 20 layer model with activation function: max_x_sigmoid\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.368309  [   64/50000]\n",
      "loss: 0.475862  [ 6464/50000]\n",
      "loss: 0.364805  [12864/50000]\n",
      "loss: 0.521528  [19264/50000]\n",
      "loss: 0.655674  [25664/50000]\n",
      "loss: 0.835961  [32064/50000]\n",
      "loss: 0.575536  [38464/50000]\n",
      "loss: 0.482475  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515004 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.432974  [   64/50000]\n",
      "loss: 0.586704  [ 6464/50000]\n",
      "loss: 0.279422  [12864/50000]\n",
      "loss: 0.531659  [19264/50000]\n",
      "loss: 0.564877  [25664/50000]\n",
      "loss: 0.846933  [32064/50000]\n",
      "loss: 0.484522  [38464/50000]\n",
      "loss: 0.457927  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.514386 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.387432  [   64/50000]\n",
      "loss: 0.468783  [ 6464/50000]\n",
      "loss: 0.354798  [12864/50000]\n",
      "loss: 0.567977  [19264/50000]\n",
      "loss: 0.523361  [25664/50000]\n",
      "loss: 0.775509  [32064/50000]\n",
      "loss: 0.576924  [38464/50000]\n",
      "loss: 0.435839  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.516693 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.386451  [   64/50000]\n",
      "loss: 0.529050  [ 6464/50000]\n",
      "loss: 0.293201  [12864/50000]\n",
      "loss: 0.537649  [19264/50000]\n",
      "loss: 0.460099  [25664/50000]\n",
      "loss: 0.703584  [32064/50000]\n",
      "loss: 0.567941  [38464/50000]\n",
      "loss: 0.410810  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.516222 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.479457  [   64/50000]\n",
      "loss: 0.439035  [ 6464/50000]\n",
      "loss: 0.393697  [12864/50000]\n",
      "loss: 0.577630  [19264/50000]\n",
      "loss: 0.596009  [25664/50000]\n",
      "loss: 0.754021  [32064/50000]\n",
      "loss: 0.540566  [38464/50000]\n",
      "loss: 0.531176  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.514196 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.440353  [   64/50000]\n",
      "loss: 0.552396  [ 6464/50000]\n",
      "loss: 0.321879  [12864/50000]\n",
      "loss: 0.541699  [19264/50000]\n",
      "loss: 0.676007  [25664/50000]\n",
      "loss: 0.726464  [32064/50000]\n",
      "loss: 0.413982  [38464/50000]\n",
      "loss: 0.526468  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514390 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.388956  [   64/50000]\n",
      "loss: 0.459747  [ 6464/50000]\n",
      "loss: 0.394630  [12864/50000]\n",
      "loss: 0.524305  [19264/50000]\n",
      "loss: 0.489076  [25664/50000]\n",
      "loss: 0.665959  [32064/50000]\n",
      "loss: 0.560576  [38464/50000]\n",
      "loss: 0.571839  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514706 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.445175  [   64/50000]\n",
      "loss: 0.494455  [ 6464/50000]\n",
      "loss: 0.296105  [12864/50000]\n",
      "loss: 0.582420  [19264/50000]\n",
      "loss: 0.684638  [25664/50000]\n",
      "loss: 0.713579  [32064/50000]\n",
      "loss: 0.502567  [38464/50000]\n",
      "loss: 0.476957  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515149 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.425888  [   64/50000]\n",
      "loss: 0.550441  [ 6464/50000]\n",
      "loss: 0.401448  [12864/50000]\n",
      "loss: 0.564244  [19264/50000]\n",
      "loss: 0.552038  [25664/50000]\n",
      "loss: 0.636987  [32064/50000]\n",
      "loss: 0.614470  [38464/50000]\n",
      "loss: 0.503936  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.513729 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.488883  [   64/50000]\n",
      "loss: 0.448717  [ 6464/50000]\n",
      "loss: 0.313529  [12864/50000]\n",
      "loss: 0.721000  [19264/50000]\n",
      "loss: 0.608342  [25664/50000]\n",
      "loss: 0.707247  [32064/50000]\n",
      "loss: 0.493226  [38464/50000]\n",
      "loss: 0.489694  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.512833 \n",
      "\n",
      "Done!\n",
      "Evaluating 20 layer model with activation function: cosx_minus_x\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.350569  [   64/50000]\n",
      "loss: 0.542935  [ 6464/50000]\n",
      "loss: 0.354772  [12864/50000]\n",
      "loss: 0.495392  [19264/50000]\n",
      "loss: 0.467895  [25664/50000]\n",
      "loss: 0.684292  [32064/50000]\n",
      "loss: 0.490241  [38464/50000]\n",
      "loss: 0.399149  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.516315 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.376112  [   64/50000]\n",
      "loss: 0.505460  [ 6464/50000]\n",
      "loss: 0.334862  [12864/50000]\n",
      "loss: 0.497054  [19264/50000]\n",
      "loss: 0.585493  [25664/50000]\n",
      "loss: 0.672818  [32064/50000]\n",
      "loss: 0.487954  [38464/50000]\n",
      "loss: 0.396793  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.516176 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.431159  [   64/50000]\n",
      "loss: 0.504329  [ 6464/50000]\n",
      "loss: 0.312575  [12864/50000]\n",
      "loss: 0.543546  [19264/50000]\n",
      "loss: 0.514019  [25664/50000]\n",
      "loss: 0.682029  [32064/50000]\n",
      "loss: 0.567005  [38464/50000]\n",
      "loss: 0.448449  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515102 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.433686  [   64/50000]\n",
      "loss: 0.498132  [ 6464/50000]\n",
      "loss: 0.330020  [12864/50000]\n",
      "loss: 0.510166  [19264/50000]\n",
      "loss: 0.555740  [25664/50000]\n",
      "loss: 0.757901  [32064/50000]\n",
      "loss: 0.492540  [38464/50000]\n",
      "loss: 0.516159  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.513980 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.340179  [   64/50000]\n",
      "loss: 0.550173  [ 6464/50000]\n",
      "loss: 0.353394  [12864/50000]\n",
      "loss: 0.459322  [19264/50000]\n",
      "loss: 0.553611  [25664/50000]\n",
      "loss: 0.732018  [32064/50000]\n",
      "loss: 0.504203  [38464/50000]\n",
      "loss: 0.503938  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.513608 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.425317  [   64/50000]\n",
      "loss: 0.547133  [ 6464/50000]\n",
      "loss: 0.321096  [12864/50000]\n",
      "loss: 0.588684  [19264/50000]\n",
      "loss: 0.575871  [25664/50000]\n",
      "loss: 0.680813  [32064/50000]\n",
      "loss: 0.528433  [38464/50000]\n",
      "loss: 0.442499  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.513585 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.393859  [   64/50000]\n",
      "loss: 0.589192  [ 6464/50000]\n",
      "loss: 0.325107  [12864/50000]\n",
      "loss: 0.609821  [19264/50000]\n",
      "loss: 0.523788  [25664/50000]\n",
      "loss: 0.763588  [32064/50000]\n",
      "loss: 0.523401  [38464/50000]\n",
      "loss: 0.478206  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514564 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.381094  [   64/50000]\n",
      "loss: 0.472042  [ 6464/50000]\n",
      "loss: 0.297921  [12864/50000]\n",
      "loss: 0.565468  [19264/50000]\n",
      "loss: 0.530005  [25664/50000]\n",
      "loss: 0.782641  [32064/50000]\n",
      "loss: 0.506701  [38464/50000]\n",
      "loss: 0.467562  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.512899 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.362948  [   64/50000]\n",
      "loss: 0.503588  [ 6464/50000]\n",
      "loss: 0.396657  [12864/50000]\n",
      "loss: 0.588449  [19264/50000]\n",
      "loss: 0.585029  [25664/50000]\n",
      "loss: 0.715225  [32064/50000]\n",
      "loss: 0.585895  [38464/50000]\n",
      "loss: 0.514714  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514348 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.459583  [   64/50000]\n",
      "loss: 0.529107  [ 6464/50000]\n",
      "loss: 0.327144  [12864/50000]\n",
      "loss: 0.539824  [19264/50000]\n",
      "loss: 0.498397  [25664/50000]\n",
      "loss: 0.677861  [32064/50000]\n",
      "loss: 0.525461  [38464/50000]\n",
      "loss: 0.451013  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515357 \n",
      "\n",
      "Done!\n",
      "Evaluating 20 layer model with activation function: lrelu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.351696  [   64/50000]\n",
      "loss: 0.523973  [ 6464/50000]\n",
      "loss: 0.377592  [12864/50000]\n",
      "loss: 0.599843  [19264/50000]\n",
      "loss: 0.578191  [25664/50000]\n",
      "loss: 0.578725  [32064/50000]\n",
      "loss: 0.583424  [38464/50000]\n",
      "loss: 0.433430  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514074 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.334150  [   64/50000]\n",
      "loss: 0.546241  [ 6464/50000]\n",
      "loss: 0.367257  [12864/50000]\n",
      "loss: 0.496580  [19264/50000]\n",
      "loss: 0.559843  [25664/50000]\n",
      "loss: 0.715238  [32064/50000]\n",
      "loss: 0.517274  [38464/50000]\n",
      "loss: 0.540111  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.515799 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.345154  [   64/50000]\n",
      "loss: 0.524828  [ 6464/50000]\n",
      "loss: 0.337839  [12864/50000]\n",
      "loss: 0.577139  [19264/50000]\n",
      "loss: 0.559936  [25664/50000]\n",
      "loss: 0.704009  [32064/50000]\n",
      "loss: 0.432908  [38464/50000]\n",
      "loss: 0.531659  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.515392 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.435737  [   64/50000]\n",
      "loss: 0.482181  [ 6464/50000]\n",
      "loss: 0.378846  [12864/50000]\n",
      "loss: 0.504889  [19264/50000]\n",
      "loss: 0.513635  [25664/50000]\n",
      "loss: 0.675837  [32064/50000]\n",
      "loss: 0.513948  [38464/50000]\n",
      "loss: 0.356705  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515076 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.418863  [   64/50000]\n",
      "loss: 0.558999  [ 6464/50000]\n",
      "loss: 0.333743  [12864/50000]\n",
      "loss: 0.571964  [19264/50000]\n",
      "loss: 0.543808  [25664/50000]\n",
      "loss: 0.716787  [32064/50000]\n",
      "loss: 0.417323  [38464/50000]\n",
      "loss: 0.503567  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514316 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.450936  [   64/50000]\n",
      "loss: 0.474003  [ 6464/50000]\n",
      "loss: 0.371413  [12864/50000]\n",
      "loss: 0.563090  [19264/50000]\n",
      "loss: 0.556971  [25664/50000]\n",
      "loss: 0.701657  [32064/50000]\n",
      "loss: 0.566555  [38464/50000]\n",
      "loss: 0.509828  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.513278 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.413088  [   64/50000]\n",
      "loss: 0.483300  [ 6464/50000]\n",
      "loss: 0.270628  [12864/50000]\n",
      "loss: 0.585603  [19264/50000]\n",
      "loss: 0.425873  [25664/50000]\n",
      "loss: 0.777393  [32064/50000]\n",
      "loss: 0.489016  [38464/50000]\n",
      "loss: 0.539426  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.513959 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.494463  [   64/50000]\n",
      "loss: 0.553054  [ 6464/50000]\n",
      "loss: 0.263283  [12864/50000]\n",
      "loss: 0.585400  [19264/50000]\n",
      "loss: 0.526320  [25664/50000]\n",
      "loss: 0.712098  [32064/50000]\n",
      "loss: 0.503005  [38464/50000]\n",
      "loss: 0.432114  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514739 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.462208  [   64/50000]\n",
      "loss: 0.510675  [ 6464/50000]\n",
      "loss: 0.388169  [12864/50000]\n",
      "loss: 0.585923  [19264/50000]\n",
      "loss: 0.569543  [25664/50000]\n",
      "loss: 0.772392  [32064/50000]\n",
      "loss: 0.617602  [38464/50000]\n",
      "loss: 0.592370  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.513500 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.402486  [   64/50000]\n",
      "loss: 0.539106  [ 6464/50000]\n",
      "loss: 0.357861  [12864/50000]\n",
      "loss: 0.601108  [19264/50000]\n",
      "loss: 0.483449  [25664/50000]\n",
      "loss: 0.744673  [32064/50000]\n",
      "loss: 0.558056  [38464/50000]\n",
      "loss: 0.448922  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514616 \n",
      "\n",
      "Done!\n",
      "Evaluating 20 layer model with activation function: prelu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.470996  [   64/50000]\n",
      "loss: 0.511729  [ 6464/50000]\n",
      "loss: 0.374880  [12864/50000]\n",
      "loss: 0.525521  [19264/50000]\n",
      "loss: 0.590799  [25664/50000]\n",
      "loss: 0.810932  [32064/50000]\n",
      "loss: 0.462812  [38464/50000]\n",
      "loss: 0.567869  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.512923 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.377988  [   64/50000]\n",
      "loss: 0.511800  [ 6464/50000]\n",
      "loss: 0.343532  [12864/50000]\n",
      "loss: 0.591784  [19264/50000]\n",
      "loss: 0.510686  [25664/50000]\n",
      "loss: 0.774171  [32064/50000]\n",
      "loss: 0.612077  [38464/50000]\n",
      "loss: 0.494828  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514161 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.358694  [   64/50000]\n",
      "loss: 0.573645  [ 6464/50000]\n",
      "loss: 0.310891  [12864/50000]\n",
      "loss: 0.537088  [19264/50000]\n",
      "loss: 0.528072  [25664/50000]\n",
      "loss: 0.739217  [32064/50000]\n",
      "loss: 0.550072  [38464/50000]\n",
      "loss: 0.500788  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515256 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.411624  [   64/50000]\n",
      "loss: 0.529220  [ 6464/50000]\n",
      "loss: 0.313647  [12864/50000]\n",
      "loss: 0.605479  [19264/50000]\n",
      "loss: 0.593180  [25664/50000]\n",
      "loss: 0.695952  [32064/50000]\n",
      "loss: 0.493573  [38464/50000]\n",
      "loss: 0.486208  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.513999 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.286343  [   64/50000]\n",
      "loss: 0.531493  [ 6464/50000]\n",
      "loss: 0.337515  [12864/50000]\n",
      "loss: 0.594389  [19264/50000]\n",
      "loss: 0.613636  [25664/50000]\n",
      "loss: 0.772513  [32064/50000]\n",
      "loss: 0.619391  [38464/50000]\n",
      "loss: 0.504017  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514551 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.460387  [   64/50000]\n",
      "loss: 0.454698  [ 6464/50000]\n",
      "loss: 0.360606  [12864/50000]\n",
      "loss: 0.588511  [19264/50000]\n",
      "loss: 0.638040  [25664/50000]\n",
      "loss: 0.755959  [32064/50000]\n",
      "loss: 0.566190  [38464/50000]\n",
      "loss: 0.438595  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.515507 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.422872  [   64/50000]\n",
      "loss: 0.488138  [ 6464/50000]\n",
      "loss: 0.385816  [12864/50000]\n",
      "loss: 0.563451  [19264/50000]\n",
      "loss: 0.586748  [25664/50000]\n",
      "loss: 0.672364  [32064/50000]\n",
      "loss: 0.561796  [38464/50000]\n",
      "loss: 0.468035  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.512740 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.437798  [   64/50000]\n",
      "loss: 0.500209  [ 6464/50000]\n",
      "loss: 0.342546  [12864/50000]\n",
      "loss: 0.564404  [19264/50000]\n",
      "loss: 0.525119  [25664/50000]\n",
      "loss: 0.633496  [32064/50000]\n",
      "loss: 0.539147  [38464/50000]\n",
      "loss: 0.423414  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.514036 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.427604  [   64/50000]\n",
      "loss: 0.523304  [ 6464/50000]\n",
      "loss: 0.371829  [12864/50000]\n",
      "loss: 0.575376  [19264/50000]\n",
      "loss: 0.522841  [25664/50000]\n",
      "loss: 0.808484  [32064/50000]\n",
      "loss: 0.487171  [38464/50000]\n",
      "loss: 0.566630  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.513503 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.373314  [   64/50000]\n",
      "loss: 0.536658  [ 6464/50000]\n",
      "loss: 0.359463  [12864/50000]\n",
      "loss: 0.687971  [19264/50000]\n",
      "loss: 0.522955  [25664/50000]\n",
      "loss: 0.620609  [32064/50000]\n",
      "loss: 0.543127  [38464/50000]\n",
      "loss: 0.596755  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515916 \n",
      "\n",
      "Done!\n",
      "Evaluating 20 layer model with activation function: softplus\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.395849  [   64/50000]\n",
      "loss: 0.482274  [ 6464/50000]\n",
      "loss: 0.329386  [12864/50000]\n",
      "loss: 0.578784  [19264/50000]\n",
      "loss: 0.530863  [25664/50000]\n",
      "loss: 0.641828  [32064/50000]\n",
      "loss: 0.510375  [38464/50000]\n",
      "loss: 0.428428  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.513013 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.416872  [   64/50000]\n",
      "loss: 0.467943  [ 6464/50000]\n",
      "loss: 0.339615  [12864/50000]\n",
      "loss: 0.519682  [19264/50000]\n",
      "loss: 0.588165  [25664/50000]\n",
      "loss: 0.632119  [32064/50000]\n",
      "loss: 0.542918  [38464/50000]\n",
      "loss: 0.499495  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514150 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.376879  [   64/50000]\n",
      "loss: 0.459736  [ 6464/50000]\n",
      "loss: 0.352112  [12864/50000]\n",
      "loss: 0.615510  [19264/50000]\n",
      "loss: 0.540747  [25664/50000]\n",
      "loss: 0.761042  [32064/50000]\n",
      "loss: 0.564161  [38464/50000]\n",
      "loss: 0.457367  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.513451 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.362722  [   64/50000]\n",
      "loss: 0.539635  [ 6464/50000]\n",
      "loss: 0.330324  [12864/50000]\n",
      "loss: 0.541933  [19264/50000]\n",
      "loss: 0.651720  [25664/50000]\n",
      "loss: 0.686956  [32064/50000]\n",
      "loss: 0.566923  [38464/50000]\n",
      "loss: 0.355602  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.514977 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.410645  [   64/50000]\n",
      "loss: 0.575692  [ 6464/50000]\n",
      "loss: 0.296977  [12864/50000]\n",
      "loss: 0.617859  [19264/50000]\n",
      "loss: 0.468336  [25664/50000]\n",
      "loss: 0.637717  [32064/50000]\n",
      "loss: 0.513331  [38464/50000]\n",
      "loss: 0.432637  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.516299 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.407935  [   64/50000]\n",
      "loss: 0.599759  [ 6464/50000]\n",
      "loss: 0.302223  [12864/50000]\n",
      "loss: 0.603723  [19264/50000]\n",
      "loss: 0.600922  [25664/50000]\n",
      "loss: 0.682005  [32064/50000]\n",
      "loss: 0.503859  [38464/50000]\n",
      "loss: 0.451073  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.513869 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.405148  [   64/50000]\n",
      "loss: 0.456469  [ 6464/50000]\n",
      "loss: 0.388954  [12864/50000]\n",
      "loss: 0.636112  [19264/50000]\n",
      "loss: 0.507837  [25664/50000]\n",
      "loss: 0.734985  [32064/50000]\n",
      "loss: 0.463125  [38464/50000]\n",
      "loss: 0.466796  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514431 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.335037  [   64/50000]\n",
      "loss: 0.487047  [ 6464/50000]\n",
      "loss: 0.366201  [12864/50000]\n",
      "loss: 0.557167  [19264/50000]\n",
      "loss: 0.486628  [25664/50000]\n",
      "loss: 0.781442  [32064/50000]\n",
      "loss: 0.537921  [38464/50000]\n",
      "loss: 0.455576  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514281 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.466038  [   64/50000]\n",
      "loss: 0.506759  [ 6464/50000]\n",
      "loss: 0.374476  [12864/50000]\n",
      "loss: 0.601389  [19264/50000]\n",
      "loss: 0.616908  [25664/50000]\n",
      "loss: 0.675000  [32064/50000]\n",
      "loss: 0.525917  [38464/50000]\n",
      "loss: 0.508436  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514296 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.359513  [   64/50000]\n",
      "loss: 0.492266  [ 6464/50000]\n",
      "loss: 0.314440  [12864/50000]\n",
      "loss: 0.539033  [19264/50000]\n",
      "loss: 0.580949  [25664/50000]\n",
      "loss: 0.731939  [32064/50000]\n",
      "loss: 0.440299  [38464/50000]\n",
      "loss: 0.521807  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514607 \n",
      "\n",
      "Done!\n",
      "Evaluating 32 layer model with activation function: relu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.367942  [   64/50000]\n",
      "loss: 0.522244  [ 6464/50000]\n",
      "loss: 0.394072  [12864/50000]\n",
      "loss: 0.522785  [19264/50000]\n",
      "loss: 0.468204  [25664/50000]\n",
      "loss: 0.774610  [32064/50000]\n",
      "loss: 0.550608  [38464/50000]\n",
      "loss: 0.484837  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.513658 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.450355  [   64/50000]\n",
      "loss: 0.467170  [ 6464/50000]\n",
      "loss: 0.354434  [12864/50000]\n",
      "loss: 0.546975  [19264/50000]\n",
      "loss: 0.516019  [25664/50000]\n",
      "loss: 0.775509  [32064/50000]\n",
      "loss: 0.601035  [38464/50000]\n",
      "loss: 0.493661  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514501 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.454629  [   64/50000]\n",
      "loss: 0.511246  [ 6464/50000]\n",
      "loss: 0.357598  [12864/50000]\n",
      "loss: 0.580547  [19264/50000]\n",
      "loss: 0.472099  [25664/50000]\n",
      "loss: 0.716899  [32064/50000]\n",
      "loss: 0.520092  [38464/50000]\n",
      "loss: 0.495754  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.516125 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.411568  [   64/50000]\n",
      "loss: 0.464667  [ 6464/50000]\n",
      "loss: 0.338175  [12864/50000]\n",
      "loss: 0.490743  [19264/50000]\n",
      "loss: 0.618689  [25664/50000]\n",
      "loss: 0.755334  [32064/50000]\n",
      "loss: 0.493408  [38464/50000]\n",
      "loss: 0.415592  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514463 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.357564  [   64/50000]\n",
      "loss: 0.578006  [ 6464/50000]\n",
      "loss: 0.280887  [12864/50000]\n",
      "loss: 0.587275  [19264/50000]\n",
      "loss: 0.477630  [25664/50000]\n",
      "loss: 0.620868  [32064/50000]\n",
      "loss: 0.551177  [38464/50000]\n",
      "loss: 0.549927  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.513789 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.367226  [   64/50000]\n",
      "loss: 0.506982  [ 6464/50000]\n",
      "loss: 0.331825  [12864/50000]\n",
      "loss: 0.609418  [19264/50000]\n",
      "loss: 0.599883  [25664/50000]\n",
      "loss: 0.795888  [32064/50000]\n",
      "loss: 0.504551  [38464/50000]\n",
      "loss: 0.466279  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.514776 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.379240  [   64/50000]\n",
      "loss: 0.532889  [ 6464/50000]\n",
      "loss: 0.362999  [12864/50000]\n",
      "loss: 0.583832  [19264/50000]\n",
      "loss: 0.610377  [25664/50000]\n",
      "loss: 0.723434  [32064/50000]\n",
      "loss: 0.581338  [38464/50000]\n",
      "loss: 0.487476  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515379 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.442306  [   64/50000]\n",
      "loss: 0.513333  [ 6464/50000]\n",
      "loss: 0.394825  [12864/50000]\n",
      "loss: 0.560397  [19264/50000]\n",
      "loss: 0.493201  [25664/50000]\n",
      "loss: 0.883132  [32064/50000]\n",
      "loss: 0.557203  [38464/50000]\n",
      "loss: 0.492768  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514167 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.459942  [   64/50000]\n",
      "loss: 0.484873  [ 6464/50000]\n",
      "loss: 0.395388  [12864/50000]\n",
      "loss: 0.567628  [19264/50000]\n",
      "loss: 0.532991  [25664/50000]\n",
      "loss: 0.731792  [32064/50000]\n",
      "loss: 0.525692  [38464/50000]\n",
      "loss: 0.528555  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515643 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.429024  [   64/50000]\n",
      "loss: 0.517063  [ 6464/50000]\n",
      "loss: 0.348526  [12864/50000]\n",
      "loss: 0.582639  [19264/50000]\n",
      "loss: 0.600365  [25664/50000]\n",
      "loss: 0.770229  [32064/50000]\n",
      "loss: 0.502223  [38464/50000]\n",
      "loss: 0.529603  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.516246 \n",
      "\n",
      "Done!\n",
      "Evaluating 32 layer model with activation function: silu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.454045  [   64/50000]\n",
      "loss: 0.540432  [ 6464/50000]\n",
      "loss: 0.307074  [12864/50000]\n",
      "loss: 0.584564  [19264/50000]\n",
      "loss: 0.507708  [25664/50000]\n",
      "loss: 0.845562  [32064/50000]\n",
      "loss: 0.526380  [38464/50000]\n",
      "loss: 0.408781  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.516127 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.367923  [   64/50000]\n",
      "loss: 0.531507  [ 6464/50000]\n",
      "loss: 0.369502  [12864/50000]\n",
      "loss: 0.478503  [19264/50000]\n",
      "loss: 0.562533  [25664/50000]\n",
      "loss: 0.714236  [32064/50000]\n",
      "loss: 0.507679  [38464/50000]\n",
      "loss: 0.519479  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514996 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.442480  [   64/50000]\n",
      "loss: 0.503537  [ 6464/50000]\n",
      "loss: 0.318528  [12864/50000]\n",
      "loss: 0.602005  [19264/50000]\n",
      "loss: 0.533060  [25664/50000]\n",
      "loss: 0.793838  [32064/50000]\n",
      "loss: 0.587930  [38464/50000]\n",
      "loss: 0.453200  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.513256 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.440240  [   64/50000]\n",
      "loss: 0.499395  [ 6464/50000]\n",
      "loss: 0.292523  [12864/50000]\n",
      "loss: 0.625803  [19264/50000]\n",
      "loss: 0.441830  [25664/50000]\n",
      "loss: 0.728923  [32064/50000]\n",
      "loss: 0.544117  [38464/50000]\n",
      "loss: 0.541770  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515114 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.365682  [   64/50000]\n",
      "loss: 0.609465  [ 6464/50000]\n",
      "loss: 0.333505  [12864/50000]\n",
      "loss: 0.567785  [19264/50000]\n",
      "loss: 0.498094  [25664/50000]\n",
      "loss: 0.744296  [32064/50000]\n",
      "loss: 0.507399  [38464/50000]\n",
      "loss: 0.512111  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.515167 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.435170  [   64/50000]\n",
      "loss: 0.592512  [ 6464/50000]\n",
      "loss: 0.372437  [12864/50000]\n",
      "loss: 0.583765  [19264/50000]\n",
      "loss: 0.460101  [25664/50000]\n",
      "loss: 0.733153  [32064/50000]\n",
      "loss: 0.519688  [38464/50000]\n",
      "loss: 0.627485  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.514470 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.476933  [   64/50000]\n",
      "loss: 0.558620  [ 6464/50000]\n",
      "loss: 0.329517  [12864/50000]\n",
      "loss: 0.557336  [19264/50000]\n",
      "loss: 0.530299  [25664/50000]\n",
      "loss: 0.670880  [32064/50000]\n",
      "loss: 0.476697  [38464/50000]\n",
      "loss: 0.513783  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.514032 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.402181  [   64/50000]\n",
      "loss: 0.559951  [ 6464/50000]\n",
      "loss: 0.350411  [12864/50000]\n",
      "loss: 0.558931  [19264/50000]\n",
      "loss: 0.527208  [25664/50000]\n",
      "loss: 0.587723  [32064/50000]\n",
      "loss: 0.469623  [38464/50000]\n",
      "loss: 0.566042  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.512146 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.457876  [   64/50000]\n",
      "loss: 0.485076  [ 6464/50000]\n",
      "loss: 0.322957  [12864/50000]\n",
      "loss: 0.571326  [19264/50000]\n",
      "loss: 0.521640  [25664/50000]\n",
      "loss: 0.740488  [32064/50000]\n",
      "loss: 0.510708  [38464/50000]\n",
      "loss: 0.493452  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515288 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.389277  [   64/50000]\n",
      "loss: 0.454118  [ 6464/50000]\n",
      "loss: 0.445157  [12864/50000]\n",
      "loss: 0.549758  [19264/50000]\n",
      "loss: 0.598812  [25664/50000]\n",
      "loss: 0.811365  [32064/50000]\n",
      "loss: 0.565994  [38464/50000]\n",
      "loss: 0.485556  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514638 \n",
      "\n",
      "Done!\n",
      "Evaluating 32 layer model with activation function: max_x_sigmoid\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.362142  [   64/50000]\n",
      "loss: 0.573815  [ 6464/50000]\n",
      "loss: 0.342516  [12864/50000]\n",
      "loss: 0.477392  [19264/50000]\n",
      "loss: 0.601368  [25664/50000]\n",
      "loss: 0.717353  [32064/50000]\n",
      "loss: 0.552358  [38464/50000]\n",
      "loss: 0.529310  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.514782 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.356035  [   64/50000]\n",
      "loss: 0.673409  [ 6464/50000]\n",
      "loss: 0.334084  [12864/50000]\n",
      "loss: 0.605709  [19264/50000]\n",
      "loss: 0.498368  [25664/50000]\n",
      "loss: 0.828864  [32064/50000]\n",
      "loss: 0.459146  [38464/50000]\n",
      "loss: 0.462077  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.514831 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.353194  [   64/50000]\n",
      "loss: 0.519690  [ 6464/50000]\n",
      "loss: 0.358943  [12864/50000]\n",
      "loss: 0.599379  [19264/50000]\n",
      "loss: 0.628677  [25664/50000]\n",
      "loss: 0.765437  [32064/50000]\n",
      "loss: 0.554512  [38464/50000]\n",
      "loss: 0.494577  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515750 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.489229  [   64/50000]\n",
      "loss: 0.529556  [ 6464/50000]\n",
      "loss: 0.328346  [12864/50000]\n",
      "loss: 0.507170  [19264/50000]\n",
      "loss: 0.487405  [25664/50000]\n",
      "loss: 0.722042  [32064/50000]\n",
      "loss: 0.449200  [38464/50000]\n",
      "loss: 0.528918  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.513858 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.368776  [   64/50000]\n",
      "loss: 0.544599  [ 6464/50000]\n",
      "loss: 0.382185  [12864/50000]\n",
      "loss: 0.600064  [19264/50000]\n",
      "loss: 0.651078  [25664/50000]\n",
      "loss: 0.752826  [32064/50000]\n",
      "loss: 0.479107  [38464/50000]\n",
      "loss: 0.501521  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.512074 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.444317  [   64/50000]\n",
      "loss: 0.552598  [ 6464/50000]\n",
      "loss: 0.302583  [12864/50000]\n",
      "loss: 0.516350  [19264/50000]\n",
      "loss: 0.611266  [25664/50000]\n",
      "loss: 0.660393  [32064/50000]\n",
      "loss: 0.543522  [38464/50000]\n",
      "loss: 0.460453  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515552 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.424394  [   64/50000]\n",
      "loss: 0.517186  [ 6464/50000]\n",
      "loss: 0.320105  [12864/50000]\n",
      "loss: 0.613452  [19264/50000]\n",
      "loss: 0.548533  [25664/50000]\n",
      "loss: 0.682656  [32064/50000]\n",
      "loss: 0.566759  [38464/50000]\n",
      "loss: 0.491561  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514306 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.350789  [   64/50000]\n",
      "loss: 0.524887  [ 6464/50000]\n",
      "loss: 0.322175  [12864/50000]\n",
      "loss: 0.546324  [19264/50000]\n",
      "loss: 0.489015  [25664/50000]\n",
      "loss: 0.790357  [32064/50000]\n",
      "loss: 0.502781  [38464/50000]\n",
      "loss: 0.467376  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514037 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.381307  [   64/50000]\n",
      "loss: 0.505284  [ 6464/50000]\n",
      "loss: 0.335187  [12864/50000]\n",
      "loss: 0.563660  [19264/50000]\n",
      "loss: 0.449324  [25664/50000]\n",
      "loss: 0.772855  [32064/50000]\n",
      "loss: 0.569618  [38464/50000]\n",
      "loss: 0.458130  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514481 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.372835  [   64/50000]\n",
      "loss: 0.428245  [ 6464/50000]\n",
      "loss: 0.397740  [12864/50000]\n",
      "loss: 0.531665  [19264/50000]\n",
      "loss: 0.518261  [25664/50000]\n",
      "loss: 0.635655  [32064/50000]\n",
      "loss: 0.553227  [38464/50000]\n",
      "loss: 0.423141  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.512704 \n",
      "\n",
      "Done!\n",
      "Evaluating 32 layer model with activation function: cosx_minus_x\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.418156  [   64/50000]\n",
      "loss: 0.470446  [ 6464/50000]\n",
      "loss: 0.368491  [12864/50000]\n",
      "loss: 0.595882  [19264/50000]\n",
      "loss: 0.647130  [25664/50000]\n",
      "loss: 0.797210  [32064/50000]\n",
      "loss: 0.477166  [38464/50000]\n",
      "loss: 0.482025  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515878 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.451968  [   64/50000]\n",
      "loss: 0.501329  [ 6464/50000]\n",
      "loss: 0.330274  [12864/50000]\n",
      "loss: 0.628867  [19264/50000]\n",
      "loss: 0.557665  [25664/50000]\n",
      "loss: 0.714784  [32064/50000]\n",
      "loss: 0.450758  [38464/50000]\n",
      "loss: 0.444515  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.510698 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.458054  [   64/50000]\n",
      "loss: 0.530178  [ 6464/50000]\n",
      "loss: 0.344112  [12864/50000]\n",
      "loss: 0.560038  [19264/50000]\n",
      "loss: 0.426880  [25664/50000]\n",
      "loss: 0.729324  [32064/50000]\n",
      "loss: 0.548134  [38464/50000]\n",
      "loss: 0.545121  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.517803 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.418411  [   64/50000]\n",
      "loss: 0.512228  [ 6464/50000]\n",
      "loss: 0.334221  [12864/50000]\n",
      "loss: 0.520399  [19264/50000]\n",
      "loss: 0.501808  [25664/50000]\n",
      "loss: 0.753597  [32064/50000]\n",
      "loss: 0.481742  [38464/50000]\n",
      "loss: 0.405556  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.513626 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.385953  [   64/50000]\n",
      "loss: 0.532982  [ 6464/50000]\n",
      "loss: 0.296820  [12864/50000]\n",
      "loss: 0.593553  [19264/50000]\n",
      "loss: 0.459385  [25664/50000]\n",
      "loss: 0.822752  [32064/50000]\n",
      "loss: 0.614135  [38464/50000]\n",
      "loss: 0.505291  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.516733 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.415982  [   64/50000]\n",
      "loss: 0.529164  [ 6464/50000]\n",
      "loss: 0.408393  [12864/50000]\n",
      "loss: 0.626876  [19264/50000]\n",
      "loss: 0.485191  [25664/50000]\n",
      "loss: 0.614105  [32064/50000]\n",
      "loss: 0.485067  [38464/50000]\n",
      "loss: 0.498486  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.513001 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.418571  [   64/50000]\n",
      "loss: 0.514863  [ 6464/50000]\n",
      "loss: 0.364321  [12864/50000]\n",
      "loss: 0.557034  [19264/50000]\n",
      "loss: 0.491182  [25664/50000]\n",
      "loss: 0.770924  [32064/50000]\n",
      "loss: 0.582024  [38464/50000]\n",
      "loss: 0.450932  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515334 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.354028  [   64/50000]\n",
      "loss: 0.505784  [ 6464/50000]\n",
      "loss: 0.272903  [12864/50000]\n",
      "loss: 0.553709  [19264/50000]\n",
      "loss: 0.487525  [25664/50000]\n",
      "loss: 0.685993  [32064/50000]\n",
      "loss: 0.536382  [38464/50000]\n",
      "loss: 0.556844  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.513767 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.356490  [   64/50000]\n",
      "loss: 0.598930  [ 6464/50000]\n",
      "loss: 0.317032  [12864/50000]\n",
      "loss: 0.546129  [19264/50000]\n",
      "loss: 0.479901  [25664/50000]\n",
      "loss: 0.717245  [32064/50000]\n",
      "loss: 0.546287  [38464/50000]\n",
      "loss: 0.433500  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514826 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.432237  [   64/50000]\n",
      "loss: 0.488014  [ 6464/50000]\n",
      "loss: 0.362787  [12864/50000]\n",
      "loss: 0.553410  [19264/50000]\n",
      "loss: 0.587928  [25664/50000]\n",
      "loss: 0.665088  [32064/50000]\n",
      "loss: 0.495745  [38464/50000]\n",
      "loss: 0.469973  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514674 \n",
      "\n",
      "Done!\n",
      "Evaluating 32 layer model with activation function: lrelu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.400688  [   64/50000]\n",
      "loss: 0.502788  [ 6464/50000]\n",
      "loss: 0.271390  [12864/50000]\n",
      "loss: 0.638556  [19264/50000]\n",
      "loss: 0.583926  [25664/50000]\n",
      "loss: 0.686463  [32064/50000]\n",
      "loss: 0.524651  [38464/50000]\n",
      "loss: 0.480782  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.512984 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.418508  [   64/50000]\n",
      "loss: 0.451158  [ 6464/50000]\n",
      "loss: 0.279768  [12864/50000]\n",
      "loss: 0.542536  [19264/50000]\n",
      "loss: 0.431185  [25664/50000]\n",
      "loss: 0.734129  [32064/50000]\n",
      "loss: 0.513378  [38464/50000]\n",
      "loss: 0.537582  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.513763 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.502944  [   64/50000]\n",
      "loss: 0.522795  [ 6464/50000]\n",
      "loss: 0.326876  [12864/50000]\n",
      "loss: 0.594139  [19264/50000]\n",
      "loss: 0.523242  [25664/50000]\n",
      "loss: 0.731936  [32064/50000]\n",
      "loss: 0.550329  [38464/50000]\n",
      "loss: 0.419268  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515870 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.419426  [   64/50000]\n",
      "loss: 0.535751  [ 6464/50000]\n",
      "loss: 0.297703  [12864/50000]\n",
      "loss: 0.503810  [19264/50000]\n",
      "loss: 0.523118  [25664/50000]\n",
      "loss: 0.767643  [32064/50000]\n",
      "loss: 0.470597  [38464/50000]\n",
      "loss: 0.506165  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514002 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.388177  [   64/50000]\n",
      "loss: 0.511218  [ 6464/50000]\n",
      "loss: 0.327478  [12864/50000]\n",
      "loss: 0.544681  [19264/50000]\n",
      "loss: 0.539559  [25664/50000]\n",
      "loss: 0.705362  [32064/50000]\n",
      "loss: 0.568406  [38464/50000]\n",
      "loss: 0.555334  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515791 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.431149  [   64/50000]\n",
      "loss: 0.538333  [ 6464/50000]\n",
      "loss: 0.367695  [12864/50000]\n",
      "loss: 0.542320  [19264/50000]\n",
      "loss: 0.527627  [25664/50000]\n",
      "loss: 0.711709  [32064/50000]\n",
      "loss: 0.524188  [38464/50000]\n",
      "loss: 0.500849  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515034 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.402279  [   64/50000]\n",
      "loss: 0.538051  [ 6464/50000]\n",
      "loss: 0.389576  [12864/50000]\n",
      "loss: 0.552168  [19264/50000]\n",
      "loss: 0.546511  [25664/50000]\n",
      "loss: 0.736107  [32064/50000]\n",
      "loss: 0.521422  [38464/50000]\n",
      "loss: 0.545962  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.513163 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.361285  [   64/50000]\n",
      "loss: 0.475024  [ 6464/50000]\n",
      "loss: 0.322177  [12864/50000]\n",
      "loss: 0.530871  [19264/50000]\n",
      "loss: 0.568844  [25664/50000]\n",
      "loss: 0.681023  [32064/50000]\n",
      "loss: 0.542916  [38464/50000]\n",
      "loss: 0.421186  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.515789 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.457867  [   64/50000]\n",
      "loss: 0.485319  [ 6464/50000]\n",
      "loss: 0.407426  [12864/50000]\n",
      "loss: 0.530021  [19264/50000]\n",
      "loss: 0.565682  [25664/50000]\n",
      "loss: 0.679806  [32064/50000]\n",
      "loss: 0.492884  [38464/50000]\n",
      "loss: 0.390869  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514308 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.391251  [   64/50000]\n",
      "loss: 0.521773  [ 6464/50000]\n",
      "loss: 0.358524  [12864/50000]\n",
      "loss: 0.522649  [19264/50000]\n",
      "loss: 0.634930  [25664/50000]\n",
      "loss: 0.704027  [32064/50000]\n",
      "loss: 0.489890  [38464/50000]\n",
      "loss: 0.463029  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514911 \n",
      "\n",
      "Done!\n",
      "Evaluating 32 layer model with activation function: prelu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.359034  [   64/50000]\n",
      "loss: 0.498873  [ 6464/50000]\n",
      "loss: 0.379622  [12864/50000]\n",
      "loss: 0.534333  [19264/50000]\n",
      "loss: 0.543877  [25664/50000]\n",
      "loss: 0.692955  [32064/50000]\n",
      "loss: 0.575946  [38464/50000]\n",
      "loss: 0.457196  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514469 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.410852  [   64/50000]\n",
      "loss: 0.543690  [ 6464/50000]\n",
      "loss: 0.340159  [12864/50000]\n",
      "loss: 0.602627  [19264/50000]\n",
      "loss: 0.591228  [25664/50000]\n",
      "loss: 0.781665  [32064/50000]\n",
      "loss: 0.487498  [38464/50000]\n",
      "loss: 0.467059  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.516932 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.403473  [   64/50000]\n",
      "loss: 0.575524  [ 6464/50000]\n",
      "loss: 0.315283  [12864/50000]\n",
      "loss: 0.567618  [19264/50000]\n",
      "loss: 0.532940  [25664/50000]\n",
      "loss: 0.782054  [32064/50000]\n",
      "loss: 0.510819  [38464/50000]\n",
      "loss: 0.463216  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514548 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.434424  [   64/50000]\n",
      "loss: 0.586187  [ 6464/50000]\n",
      "loss: 0.338395  [12864/50000]\n",
      "loss: 0.566798  [19264/50000]\n",
      "loss: 0.489755  [25664/50000]\n",
      "loss: 0.649665  [32064/50000]\n",
      "loss: 0.434073  [38464/50000]\n",
      "loss: 0.502739  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515061 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.471061  [   64/50000]\n",
      "loss: 0.504520  [ 6464/50000]\n",
      "loss: 0.383328  [12864/50000]\n",
      "loss: 0.535265  [19264/50000]\n",
      "loss: 0.544150  [25664/50000]\n",
      "loss: 0.619204  [32064/50000]\n",
      "loss: 0.565656  [38464/50000]\n",
      "loss: 0.452708  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.513580 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.362214  [   64/50000]\n",
      "loss: 0.512524  [ 6464/50000]\n",
      "loss: 0.311697  [12864/50000]\n",
      "loss: 0.574490  [19264/50000]\n",
      "loss: 0.548023  [25664/50000]\n",
      "loss: 0.696849  [32064/50000]\n",
      "loss: 0.593490  [38464/50000]\n",
      "loss: 0.457614  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514179 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.366738  [   64/50000]\n",
      "loss: 0.546152  [ 6464/50000]\n",
      "loss: 0.412778  [12864/50000]\n",
      "loss: 0.561027  [19264/50000]\n",
      "loss: 0.568836  [25664/50000]\n",
      "loss: 0.638932  [32064/50000]\n",
      "loss: 0.586959  [38464/50000]\n",
      "loss: 0.473916  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515063 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.356633  [   64/50000]\n",
      "loss: 0.467361  [ 6464/50000]\n",
      "loss: 0.355579  [12864/50000]\n",
      "loss: 0.561877  [19264/50000]\n",
      "loss: 0.533110  [25664/50000]\n",
      "loss: 0.669490  [32064/50000]\n",
      "loss: 0.540182  [38464/50000]\n",
      "loss: 0.460991  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515096 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.475388  [   64/50000]\n",
      "loss: 0.498796  [ 6464/50000]\n",
      "loss: 0.389607  [12864/50000]\n",
      "loss: 0.552973  [19264/50000]\n",
      "loss: 0.427373  [25664/50000]\n",
      "loss: 0.778836  [32064/50000]\n",
      "loss: 0.407392  [38464/50000]\n",
      "loss: 0.545768  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.511919 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.382565  [   64/50000]\n",
      "loss: 0.513440  [ 6464/50000]\n",
      "loss: 0.336594  [12864/50000]\n",
      "loss: 0.599416  [19264/50000]\n",
      "loss: 0.610014  [25664/50000]\n",
      "loss: 0.763560  [32064/50000]\n",
      "loss: 0.479719  [38464/50000]\n",
      "loss: 0.483552  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514007 \n",
      "\n",
      "Done!\n",
      "Evaluating 32 layer model with activation function: softplus\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.360685  [   64/50000]\n",
      "loss: 0.477436  [ 6464/50000]\n",
      "loss: 0.384249  [12864/50000]\n",
      "loss: 0.538435  [19264/50000]\n",
      "loss: 0.445671  [25664/50000]\n",
      "loss: 0.726951  [32064/50000]\n",
      "loss: 0.578755  [38464/50000]\n",
      "loss: 0.504687  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515415 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.434075  [   64/50000]\n",
      "loss: 0.535595  [ 6464/50000]\n",
      "loss: 0.313289  [12864/50000]\n",
      "loss: 0.512935  [19264/50000]\n",
      "loss: 0.522009  [25664/50000]\n",
      "loss: 0.788540  [32064/50000]\n",
      "loss: 0.599602  [38464/50000]\n",
      "loss: 0.484666  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.512539 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.378145  [   64/50000]\n",
      "loss: 0.527327  [ 6464/50000]\n",
      "loss: 0.334640  [12864/50000]\n",
      "loss: 0.539229  [19264/50000]\n",
      "loss: 0.543317  [25664/50000]\n",
      "loss: 0.732065  [32064/50000]\n",
      "loss: 0.474507  [38464/50000]\n",
      "loss: 0.526759  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515402 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.435742  [   64/50000]\n",
      "loss: 0.491516  [ 6464/50000]\n",
      "loss: 0.380887  [12864/50000]\n",
      "loss: 0.603224  [19264/50000]\n",
      "loss: 0.444490  [25664/50000]\n",
      "loss: 0.743869  [32064/50000]\n",
      "loss: 0.534926  [38464/50000]\n",
      "loss: 0.503705  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.513965 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.362805  [   64/50000]\n",
      "loss: 0.499694  [ 6464/50000]\n",
      "loss: 0.299836  [12864/50000]\n",
      "loss: 0.627138  [19264/50000]\n",
      "loss: 0.538256  [25664/50000]\n",
      "loss: 0.589713  [32064/50000]\n",
      "loss: 0.578800  [38464/50000]\n",
      "loss: 0.434376  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515579 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.354105  [   64/50000]\n",
      "loss: 0.532610  [ 6464/50000]\n",
      "loss: 0.320167  [12864/50000]\n",
      "loss: 0.541580  [19264/50000]\n",
      "loss: 0.541461  [25664/50000]\n",
      "loss: 0.636499  [32064/50000]\n",
      "loss: 0.544818  [38464/50000]\n",
      "loss: 0.426189  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.513468 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.476784  [   64/50000]\n",
      "loss: 0.553497  [ 6464/50000]\n",
      "loss: 0.335818  [12864/50000]\n",
      "loss: 0.678257  [19264/50000]\n",
      "loss: 0.522860  [25664/50000]\n",
      "loss: 0.755707  [32064/50000]\n",
      "loss: 0.428533  [38464/50000]\n",
      "loss: 0.516546  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.516855 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.441444  [   64/50000]\n",
      "loss: 0.467504  [ 6464/50000]\n",
      "loss: 0.343548  [12864/50000]\n",
      "loss: 0.504464  [19264/50000]\n",
      "loss: 0.661474  [25664/50000]\n",
      "loss: 0.795620  [32064/50000]\n",
      "loss: 0.484918  [38464/50000]\n",
      "loss: 0.516850  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514398 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.405595  [   64/50000]\n",
      "loss: 0.503419  [ 6464/50000]\n",
      "loss: 0.288354  [12864/50000]\n",
      "loss: 0.532716  [19264/50000]\n",
      "loss: 0.444649  [25664/50000]\n",
      "loss: 0.832005  [32064/50000]\n",
      "loss: 0.472490  [38464/50000]\n",
      "loss: 0.481185  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.512952 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.477378  [   64/50000]\n",
      "loss: 0.491768  [ 6464/50000]\n",
      "loss: 0.343208  [12864/50000]\n",
      "loss: 0.609422  [19264/50000]\n",
      "loss: 0.601894  [25664/50000]\n",
      "loss: 0.837432  [32064/50000]\n",
      "loss: 0.551700  [38464/50000]\n",
      "loss: 0.475493  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.512803 \n",
      "\n",
      "Done!\n",
      "Evaluating 44 layer model with activation function: relu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.377122  [   64/50000]\n",
      "loss: 0.453500  [ 6464/50000]\n",
      "loss: 0.390660  [12864/50000]\n",
      "loss: 0.556353  [19264/50000]\n",
      "loss: 0.564059  [25664/50000]\n",
      "loss: 0.762514  [32064/50000]\n",
      "loss: 0.537190  [38464/50000]\n",
      "loss: 0.448081  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514284 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.418000  [   64/50000]\n",
      "loss: 0.526039  [ 6464/50000]\n",
      "loss: 0.318756  [12864/50000]\n",
      "loss: 0.613424  [19264/50000]\n",
      "loss: 0.644202  [25664/50000]\n",
      "loss: 0.752279  [32064/50000]\n",
      "loss: 0.463451  [38464/50000]\n",
      "loss: 0.517991  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514125 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.428704  [   64/50000]\n",
      "loss: 0.473832  [ 6464/50000]\n",
      "loss: 0.331935  [12864/50000]\n",
      "loss: 0.609490  [19264/50000]\n",
      "loss: 0.463984  [25664/50000]\n",
      "loss: 0.757221  [32064/50000]\n",
      "loss: 0.553685  [38464/50000]\n",
      "loss: 0.401240  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515094 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.425564  [   64/50000]\n",
      "loss: 0.508425  [ 6464/50000]\n",
      "loss: 0.434529  [12864/50000]\n",
      "loss: 0.578414  [19264/50000]\n",
      "loss: 0.481007  [25664/50000]\n",
      "loss: 0.667235  [32064/50000]\n",
      "loss: 0.553921  [38464/50000]\n",
      "loss: 0.474990  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.513861 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.367363  [   64/50000]\n",
      "loss: 0.541355  [ 6464/50000]\n",
      "loss: 0.380090  [12864/50000]\n",
      "loss: 0.647785  [19264/50000]\n",
      "loss: 0.536069  [25664/50000]\n",
      "loss: 0.680602  [32064/50000]\n",
      "loss: 0.519745  [38464/50000]\n",
      "loss: 0.530009  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.516024 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.367515  [   64/50000]\n",
      "loss: 0.515838  [ 6464/50000]\n",
      "loss: 0.283813  [12864/50000]\n",
      "loss: 0.643286  [19264/50000]\n",
      "loss: 0.571145  [25664/50000]\n",
      "loss: 0.660736  [32064/50000]\n",
      "loss: 0.540551  [38464/50000]\n",
      "loss: 0.430801  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515621 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.410415  [   64/50000]\n",
      "loss: 0.565325  [ 6464/50000]\n",
      "loss: 0.300523  [12864/50000]\n",
      "loss: 0.602093  [19264/50000]\n",
      "loss: 0.612395  [25664/50000]\n",
      "loss: 0.678447  [32064/50000]\n",
      "loss: 0.524757  [38464/50000]\n",
      "loss: 0.545465  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.513777 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.449064  [   64/50000]\n",
      "loss: 0.526649  [ 6464/50000]\n",
      "loss: 0.290430  [12864/50000]\n",
      "loss: 0.591469  [19264/50000]\n",
      "loss: 0.582766  [25664/50000]\n",
      "loss: 0.672693  [32064/50000]\n",
      "loss: 0.489350  [38464/50000]\n",
      "loss: 0.482578  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515307 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.328348  [   64/50000]\n",
      "loss: 0.553442  [ 6464/50000]\n",
      "loss: 0.401480  [12864/50000]\n",
      "loss: 0.502861  [19264/50000]\n",
      "loss: 0.460242  [25664/50000]\n",
      "loss: 0.735325  [32064/50000]\n",
      "loss: 0.532354  [38464/50000]\n",
      "loss: 0.514207  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514144 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.355346  [   64/50000]\n",
      "loss: 0.447366  [ 6464/50000]\n",
      "loss: 0.327790  [12864/50000]\n",
      "loss: 0.557749  [19264/50000]\n",
      "loss: 0.509319  [25664/50000]\n",
      "loss: 0.794916  [32064/50000]\n",
      "loss: 0.529993  [38464/50000]\n",
      "loss: 0.453077  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.517389 \n",
      "\n",
      "Done!\n",
      "Evaluating 44 layer model with activation function: silu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.520206  [   64/50000]\n",
      "loss: 0.535519  [ 6464/50000]\n",
      "loss: 0.378698  [12864/50000]\n",
      "loss: 0.569942  [19264/50000]\n",
      "loss: 0.494020  [25664/50000]\n",
      "loss: 0.691342  [32064/50000]\n",
      "loss: 0.509170  [38464/50000]\n",
      "loss: 0.487614  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515547 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.470284  [   64/50000]\n",
      "loss: 0.555414  [ 6464/50000]\n",
      "loss: 0.340119  [12864/50000]\n",
      "loss: 0.531373  [19264/50000]\n",
      "loss: 0.507553  [25664/50000]\n",
      "loss: 0.838605  [32064/50000]\n",
      "loss: 0.551860  [38464/50000]\n",
      "loss: 0.449731  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514245 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.461096  [   64/50000]\n",
      "loss: 0.493137  [ 6464/50000]\n",
      "loss: 0.398139  [12864/50000]\n",
      "loss: 0.615962  [19264/50000]\n",
      "loss: 0.541579  [25664/50000]\n",
      "loss: 0.597402  [32064/50000]\n",
      "loss: 0.551017  [38464/50000]\n",
      "loss: 0.465538  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515167 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.354243  [   64/50000]\n",
      "loss: 0.499761  [ 6464/50000]\n",
      "loss: 0.374931  [12864/50000]\n",
      "loss: 0.569040  [19264/50000]\n",
      "loss: 0.618439  [25664/50000]\n",
      "loss: 0.735342  [32064/50000]\n",
      "loss: 0.573117  [38464/50000]\n",
      "loss: 0.458568  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514798 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.473186  [   64/50000]\n",
      "loss: 0.540695  [ 6464/50000]\n",
      "loss: 0.295259  [12864/50000]\n",
      "loss: 0.590945  [19264/50000]\n",
      "loss: 0.517305  [25664/50000]\n",
      "loss: 0.794128  [32064/50000]\n",
      "loss: 0.557594  [38464/50000]\n",
      "loss: 0.463299  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.512262 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.385255  [   64/50000]\n",
      "loss: 0.506170  [ 6464/50000]\n",
      "loss: 0.344763  [12864/50000]\n",
      "loss: 0.578973  [19264/50000]\n",
      "loss: 0.558218  [25664/50000]\n",
      "loss: 0.831938  [32064/50000]\n",
      "loss: 0.535169  [38464/50000]\n",
      "loss: 0.475082  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514281 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.407218  [   64/50000]\n",
      "loss: 0.507722  [ 6464/50000]\n",
      "loss: 0.315608  [12864/50000]\n",
      "loss: 0.585514  [19264/50000]\n",
      "loss: 0.536530  [25664/50000]\n",
      "loss: 0.825770  [32064/50000]\n",
      "loss: 0.436004  [38464/50000]\n",
      "loss: 0.496527  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.512031 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.367974  [   64/50000]\n",
      "loss: 0.507358  [ 6464/50000]\n",
      "loss: 0.281099  [12864/50000]\n",
      "loss: 0.566666  [19264/50000]\n",
      "loss: 0.547419  [25664/50000]\n",
      "loss: 0.712413  [32064/50000]\n",
      "loss: 0.504288  [38464/50000]\n",
      "loss: 0.490816  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.513718 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.423244  [   64/50000]\n",
      "loss: 0.490189  [ 6464/50000]\n",
      "loss: 0.326140  [12864/50000]\n",
      "loss: 0.565731  [19264/50000]\n",
      "loss: 0.604078  [25664/50000]\n",
      "loss: 0.643433  [32064/50000]\n",
      "loss: 0.518557  [38464/50000]\n",
      "loss: 0.491571  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514392 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.477644  [   64/50000]\n",
      "loss: 0.490198  [ 6464/50000]\n",
      "loss: 0.384336  [12864/50000]\n",
      "loss: 0.563691  [19264/50000]\n",
      "loss: 0.630484  [25664/50000]\n",
      "loss: 0.855645  [32064/50000]\n",
      "loss: 0.589780  [38464/50000]\n",
      "loss: 0.533731  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515164 \n",
      "\n",
      "Done!\n",
      "Evaluating 44 layer model with activation function: max_x_sigmoid\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.393864  [   64/50000]\n",
      "loss: 0.510036  [ 6464/50000]\n",
      "loss: 0.323220  [12864/50000]\n",
      "loss: 0.598990  [19264/50000]\n",
      "loss: 0.542333  [25664/50000]\n",
      "loss: 0.696999  [32064/50000]\n",
      "loss: 0.560825  [38464/50000]\n",
      "loss: 0.425375  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514482 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.464611  [   64/50000]\n",
      "loss: 0.520191  [ 6464/50000]\n",
      "loss: 0.379137  [12864/50000]\n",
      "loss: 0.487764  [19264/50000]\n",
      "loss: 0.452790  [25664/50000]\n",
      "loss: 0.761262  [32064/50000]\n",
      "loss: 0.527404  [38464/50000]\n",
      "loss: 0.386533  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.513434 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.379139  [   64/50000]\n",
      "loss: 0.488419  [ 6464/50000]\n",
      "loss: 0.322690  [12864/50000]\n",
      "loss: 0.599386  [19264/50000]\n",
      "loss: 0.568207  [25664/50000]\n",
      "loss: 0.769481  [32064/50000]\n",
      "loss: 0.455067  [38464/50000]\n",
      "loss: 0.458302  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514195 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.403636  [   64/50000]\n",
      "loss: 0.545270  [ 6464/50000]\n",
      "loss: 0.310469  [12864/50000]\n",
      "loss: 0.559091  [19264/50000]\n",
      "loss: 0.439448  [25664/50000]\n",
      "loss: 0.839239  [32064/50000]\n",
      "loss: 0.513507  [38464/50000]\n",
      "loss: 0.448939  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.513271 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.342356  [   64/50000]\n",
      "loss: 0.531344  [ 6464/50000]\n",
      "loss: 0.316819  [12864/50000]\n",
      "loss: 0.540653  [19264/50000]\n",
      "loss: 0.500041  [25664/50000]\n",
      "loss: 0.773291  [32064/50000]\n",
      "loss: 0.502717  [38464/50000]\n",
      "loss: 0.497653  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.514632 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.439928  [   64/50000]\n",
      "loss: 0.528081  [ 6464/50000]\n",
      "loss: 0.275641  [12864/50000]\n",
      "loss: 0.613805  [19264/50000]\n",
      "loss: 0.610450  [25664/50000]\n",
      "loss: 0.704594  [32064/50000]\n",
      "loss: 0.504958  [38464/50000]\n",
      "loss: 0.512811  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515172 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.431557  [   64/50000]\n",
      "loss: 0.538341  [ 6464/50000]\n",
      "loss: 0.354424  [12864/50000]\n",
      "loss: 0.532502  [19264/50000]\n",
      "loss: 0.428263  [25664/50000]\n",
      "loss: 0.825754  [32064/50000]\n",
      "loss: 0.660468  [38464/50000]\n",
      "loss: 0.503590  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.513981 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.377833  [   64/50000]\n",
      "loss: 0.438543  [ 6464/50000]\n",
      "loss: 0.387420  [12864/50000]\n",
      "loss: 0.639777  [19264/50000]\n",
      "loss: 0.484132  [25664/50000]\n",
      "loss: 0.730677  [32064/50000]\n",
      "loss: 0.529388  [38464/50000]\n",
      "loss: 0.452799  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.513613 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.403798  [   64/50000]\n",
      "loss: 0.510101  [ 6464/50000]\n",
      "loss: 0.286115  [12864/50000]\n",
      "loss: 0.488518  [19264/50000]\n",
      "loss: 0.545764  [25664/50000]\n",
      "loss: 0.797848  [32064/50000]\n",
      "loss: 0.530501  [38464/50000]\n",
      "loss: 0.423111  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514615 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.424050  [   64/50000]\n",
      "loss: 0.494612  [ 6464/50000]\n",
      "loss: 0.345471  [12864/50000]\n",
      "loss: 0.556540  [19264/50000]\n",
      "loss: 0.568220  [25664/50000]\n",
      "loss: 0.750137  [32064/50000]\n",
      "loss: 0.458930  [38464/50000]\n",
      "loss: 0.590519  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.513123 \n",
      "\n",
      "Done!\n",
      "Evaluating 44 layer model with activation function: cosx_minus_x\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.452751  [   64/50000]\n",
      "loss: 0.532130  [ 6464/50000]\n",
      "loss: 0.306346  [12864/50000]\n",
      "loss: 0.586156  [19264/50000]\n",
      "loss: 0.648072  [25664/50000]\n",
      "loss: 0.719489  [32064/50000]\n",
      "loss: 0.500837  [38464/50000]\n",
      "loss: 0.472020  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515995 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.466487  [   64/50000]\n",
      "loss: 0.552434  [ 6464/50000]\n",
      "loss: 0.394936  [12864/50000]\n",
      "loss: 0.569471  [19264/50000]\n",
      "loss: 0.582540  [25664/50000]\n",
      "loss: 0.762673  [32064/50000]\n",
      "loss: 0.512301  [38464/50000]\n",
      "loss: 0.452583  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515694 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.427017  [   64/50000]\n",
      "loss: 0.484485  [ 6464/50000]\n",
      "loss: 0.337230  [12864/50000]\n",
      "loss: 0.570742  [19264/50000]\n",
      "loss: 0.507554  [25664/50000]\n",
      "loss: 0.778816  [32064/50000]\n",
      "loss: 0.589045  [38464/50000]\n",
      "loss: 0.429685  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514641 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.412442  [   64/50000]\n",
      "loss: 0.542391  [ 6464/50000]\n",
      "loss: 0.316572  [12864/50000]\n",
      "loss: 0.560976  [19264/50000]\n",
      "loss: 0.566938  [25664/50000]\n",
      "loss: 0.746816  [32064/50000]\n",
      "loss: 0.550963  [38464/50000]\n",
      "loss: 0.475013  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514892 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.402715  [   64/50000]\n",
      "loss: 0.548814  [ 6464/50000]\n",
      "loss: 0.297733  [12864/50000]\n",
      "loss: 0.616911  [19264/50000]\n",
      "loss: 0.546154  [25664/50000]\n",
      "loss: 0.816772  [32064/50000]\n",
      "loss: 0.478747  [38464/50000]\n",
      "loss: 0.442933  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.516145 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.368386  [   64/50000]\n",
      "loss: 0.527016  [ 6464/50000]\n",
      "loss: 0.327812  [12864/50000]\n",
      "loss: 0.542150  [19264/50000]\n",
      "loss: 0.505755  [25664/50000]\n",
      "loss: 0.676136  [32064/50000]\n",
      "loss: 0.481016  [38464/50000]\n",
      "loss: 0.467481  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.516332 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.384060  [   64/50000]\n",
      "loss: 0.489617  [ 6464/50000]\n",
      "loss: 0.293832  [12864/50000]\n",
      "loss: 0.528482  [19264/50000]\n",
      "loss: 0.525229  [25664/50000]\n",
      "loss: 0.659347  [32064/50000]\n",
      "loss: 0.494910  [38464/50000]\n",
      "loss: 0.448344  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515458 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.416294  [   64/50000]\n",
      "loss: 0.485348  [ 6464/50000]\n",
      "loss: 0.329759  [12864/50000]\n",
      "loss: 0.582059  [19264/50000]\n",
      "loss: 0.565152  [25664/50000]\n",
      "loss: 0.666101  [32064/50000]\n",
      "loss: 0.451101  [38464/50000]\n",
      "loss: 0.422379  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.513623 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.359774  [   64/50000]\n",
      "loss: 0.552513  [ 6464/50000]\n",
      "loss: 0.390024  [12864/50000]\n",
      "loss: 0.521964  [19264/50000]\n",
      "loss: 0.627074  [25664/50000]\n",
      "loss: 0.739579  [32064/50000]\n",
      "loss: 0.546416  [38464/50000]\n",
      "loss: 0.553369  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.512623 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.482255  [   64/50000]\n",
      "loss: 0.479377  [ 6464/50000]\n",
      "loss: 0.377780  [12864/50000]\n",
      "loss: 0.604836  [19264/50000]\n",
      "loss: 0.599773  [25664/50000]\n",
      "loss: 0.667340  [32064/50000]\n",
      "loss: 0.567989  [38464/50000]\n",
      "loss: 0.517679  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514946 \n",
      "\n",
      "Done!\n",
      "Evaluating 44 layer model with activation function: lrelu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.433411  [   64/50000]\n",
      "loss: 0.528065  [ 6464/50000]\n",
      "loss: 0.379738  [12864/50000]\n",
      "loss: 0.589786  [19264/50000]\n",
      "loss: 0.544426  [25664/50000]\n",
      "loss: 0.798059  [32064/50000]\n",
      "loss: 0.506332  [38464/50000]\n",
      "loss: 0.461807  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.513742 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.441389  [   64/50000]\n",
      "loss: 0.516570  [ 6464/50000]\n",
      "loss: 0.296376  [12864/50000]\n",
      "loss: 0.528662  [19264/50000]\n",
      "loss: 0.552709  [25664/50000]\n",
      "loss: 0.794215  [32064/50000]\n",
      "loss: 0.475774  [38464/50000]\n",
      "loss: 0.469804  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514611 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.376450  [   64/50000]\n",
      "loss: 0.433646  [ 6464/50000]\n",
      "loss: 0.372187  [12864/50000]\n",
      "loss: 0.607433  [19264/50000]\n",
      "loss: 0.535363  [25664/50000]\n",
      "loss: 0.654252  [32064/50000]\n",
      "loss: 0.476246  [38464/50000]\n",
      "loss: 0.459022  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514328 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.366043  [   64/50000]\n",
      "loss: 0.540934  [ 6464/50000]\n",
      "loss: 0.383314  [12864/50000]\n",
      "loss: 0.544577  [19264/50000]\n",
      "loss: 0.620557  [25664/50000]\n",
      "loss: 0.705154  [32064/50000]\n",
      "loss: 0.550564  [38464/50000]\n",
      "loss: 0.432705  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.517013 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.479452  [   64/50000]\n",
      "loss: 0.514623  [ 6464/50000]\n",
      "loss: 0.347260  [12864/50000]\n",
      "loss: 0.630094  [19264/50000]\n",
      "loss: 0.544509  [25664/50000]\n",
      "loss: 0.703131  [32064/50000]\n",
      "loss: 0.598123  [38464/50000]\n",
      "loss: 0.550641  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514562 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.387118  [   64/50000]\n",
      "loss: 0.523694  [ 6464/50000]\n",
      "loss: 0.293623  [12864/50000]\n",
      "loss: 0.606224  [19264/50000]\n",
      "loss: 0.609258  [25664/50000]\n",
      "loss: 0.704442  [32064/50000]\n",
      "loss: 0.508538  [38464/50000]\n",
      "loss: 0.455686  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515212 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.427208  [   64/50000]\n",
      "loss: 0.507812  [ 6464/50000]\n",
      "loss: 0.308118  [12864/50000]\n",
      "loss: 0.543219  [19264/50000]\n",
      "loss: 0.451165  [25664/50000]\n",
      "loss: 0.700793  [32064/50000]\n",
      "loss: 0.544509  [38464/50000]\n",
      "loss: 0.453539  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.513407 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.458207  [   64/50000]\n",
      "loss: 0.465053  [ 6464/50000]\n",
      "loss: 0.297277  [12864/50000]\n",
      "loss: 0.607937  [19264/50000]\n",
      "loss: 0.623981  [25664/50000]\n",
      "loss: 0.618046  [32064/50000]\n",
      "loss: 0.544095  [38464/50000]\n",
      "loss: 0.412284  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.514224 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.379832  [   64/50000]\n",
      "loss: 0.491294  [ 6464/50000]\n",
      "loss: 0.357645  [12864/50000]\n",
      "loss: 0.551326  [19264/50000]\n",
      "loss: 0.517558  [25664/50000]\n",
      "loss: 0.701119  [32064/50000]\n",
      "loss: 0.575373  [38464/50000]\n",
      "loss: 0.605309  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.513695 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.400003  [   64/50000]\n",
      "loss: 0.446852  [ 6464/50000]\n",
      "loss: 0.326566  [12864/50000]\n",
      "loss: 0.526048  [19264/50000]\n",
      "loss: 0.506843  [25664/50000]\n",
      "loss: 0.659659  [32064/50000]\n",
      "loss: 0.589100  [38464/50000]\n",
      "loss: 0.511133  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515556 \n",
      "\n",
      "Done!\n",
      "Evaluating 44 layer model with activation function: prelu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.479519  [   64/50000]\n",
      "loss: 0.515662  [ 6464/50000]\n",
      "loss: 0.345673  [12864/50000]\n",
      "loss: 0.543264  [19264/50000]\n",
      "loss: 0.543218  [25664/50000]\n",
      "loss: 0.654691  [32064/50000]\n",
      "loss: 0.630121  [38464/50000]\n",
      "loss: 0.578894  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514715 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.379892  [   64/50000]\n",
      "loss: 0.531801  [ 6464/50000]\n",
      "loss: 0.450178  [12864/50000]\n",
      "loss: 0.594015  [19264/50000]\n",
      "loss: 0.599073  [25664/50000]\n",
      "loss: 0.739020  [32064/50000]\n",
      "loss: 0.450459  [38464/50000]\n",
      "loss: 0.440593  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.516019 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.409677  [   64/50000]\n",
      "loss: 0.500056  [ 6464/50000]\n",
      "loss: 0.339462  [12864/50000]\n",
      "loss: 0.613300  [19264/50000]\n",
      "loss: 0.613469  [25664/50000]\n",
      "loss: 0.755621  [32064/50000]\n",
      "loss: 0.478368  [38464/50000]\n",
      "loss: 0.477647  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.513572 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.385788  [   64/50000]\n",
      "loss: 0.556430  [ 6464/50000]\n",
      "loss: 0.312755  [12864/50000]\n",
      "loss: 0.593251  [19264/50000]\n",
      "loss: 0.501306  [25664/50000]\n",
      "loss: 0.696076  [32064/50000]\n",
      "loss: 0.537736  [38464/50000]\n",
      "loss: 0.497496  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.513059 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.441691  [   64/50000]\n",
      "loss: 0.506448  [ 6464/50000]\n",
      "loss: 0.340911  [12864/50000]\n",
      "loss: 0.605643  [19264/50000]\n",
      "loss: 0.568652  [25664/50000]\n",
      "loss: 0.750830  [32064/50000]\n",
      "loss: 0.515719  [38464/50000]\n",
      "loss: 0.585910  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514559 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.352711  [   64/50000]\n",
      "loss: 0.512456  [ 6464/50000]\n",
      "loss: 0.305934  [12864/50000]\n",
      "loss: 0.529251  [19264/50000]\n",
      "loss: 0.529341  [25664/50000]\n",
      "loss: 0.707727  [32064/50000]\n",
      "loss: 0.544077  [38464/50000]\n",
      "loss: 0.514957  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515308 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.440113  [   64/50000]\n",
      "loss: 0.504429  [ 6464/50000]\n",
      "loss: 0.339764  [12864/50000]\n",
      "loss: 0.599725  [19264/50000]\n",
      "loss: 0.587694  [25664/50000]\n",
      "loss: 0.785098  [32064/50000]\n",
      "loss: 0.495705  [38464/50000]\n",
      "loss: 0.453869  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515576 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.412570  [   64/50000]\n",
      "loss: 0.489270  [ 6464/50000]\n",
      "loss: 0.339168  [12864/50000]\n",
      "loss: 0.593644  [19264/50000]\n",
      "loss: 0.573681  [25664/50000]\n",
      "loss: 0.733145  [32064/50000]\n",
      "loss: 0.474938  [38464/50000]\n",
      "loss: 0.533998  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514035 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.438043  [   64/50000]\n",
      "loss: 0.497712  [ 6464/50000]\n",
      "loss: 0.364531  [12864/50000]\n",
      "loss: 0.560313  [19264/50000]\n",
      "loss: 0.511753  [25664/50000]\n",
      "loss: 0.771711  [32064/50000]\n",
      "loss: 0.503482  [38464/50000]\n",
      "loss: 0.383645  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514595 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.385621  [   64/50000]\n",
      "loss: 0.541295  [ 6464/50000]\n",
      "loss: 0.361708  [12864/50000]\n",
      "loss: 0.528858  [19264/50000]\n",
      "loss: 0.569506  [25664/50000]\n",
      "loss: 0.700050  [32064/50000]\n",
      "loss: 0.464666  [38464/50000]\n",
      "loss: 0.507559  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.512640 \n",
      "\n",
      "Done!\n",
      "Evaluating 44 layer model with activation function: softplus\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.416676  [   64/50000]\n",
      "loss: 0.506375  [ 6464/50000]\n",
      "loss: 0.308025  [12864/50000]\n",
      "loss: 0.571962  [19264/50000]\n",
      "loss: 0.631799  [25664/50000]\n",
      "loss: 0.637382  [32064/50000]\n",
      "loss: 0.499172  [38464/50000]\n",
      "loss: 0.578086  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515853 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.405244  [   64/50000]\n",
      "loss: 0.445234  [ 6464/50000]\n",
      "loss: 0.475152  [12864/50000]\n",
      "loss: 0.586950  [19264/50000]\n",
      "loss: 0.524429  [25664/50000]\n",
      "loss: 0.660138  [32064/50000]\n",
      "loss: 0.491167  [38464/50000]\n",
      "loss: 0.574262  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.516619 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.320259  [   64/50000]\n",
      "loss: 0.493872  [ 6464/50000]\n",
      "loss: 0.259675  [12864/50000]\n",
      "loss: 0.542228  [19264/50000]\n",
      "loss: 0.601383  [25664/50000]\n",
      "loss: 0.751032  [32064/50000]\n",
      "loss: 0.514271  [38464/50000]\n",
      "loss: 0.495903  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515738 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.456876  [   64/50000]\n",
      "loss: 0.540493  [ 6464/50000]\n",
      "loss: 0.347887  [12864/50000]\n",
      "loss: 0.545670  [19264/50000]\n",
      "loss: 0.484844  [25664/50000]\n",
      "loss: 0.657199  [32064/50000]\n",
      "loss: 0.525644  [38464/50000]\n",
      "loss: 0.577157  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514484 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.435104  [   64/50000]\n",
      "loss: 0.504651  [ 6464/50000]\n",
      "loss: 0.286994  [12864/50000]\n",
      "loss: 0.549977  [19264/50000]\n",
      "loss: 0.472073  [25664/50000]\n",
      "loss: 0.674379  [32064/50000]\n",
      "loss: 0.535437  [38464/50000]\n",
      "loss: 0.516937  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.512718 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.398570  [   64/50000]\n",
      "loss: 0.437239  [ 6464/50000]\n",
      "loss: 0.296632  [12864/50000]\n",
      "loss: 0.572258  [19264/50000]\n",
      "loss: 0.609762  [25664/50000]\n",
      "loss: 0.757985  [32064/50000]\n",
      "loss: 0.662193  [38464/50000]\n",
      "loss: 0.550898  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514352 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.449659  [   64/50000]\n",
      "loss: 0.543479  [ 6464/50000]\n",
      "loss: 0.323156  [12864/50000]\n",
      "loss: 0.513041  [19264/50000]\n",
      "loss: 0.598706  [25664/50000]\n",
      "loss: 0.823528  [32064/50000]\n",
      "loss: 0.544250  [38464/50000]\n",
      "loss: 0.530943  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.515843 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.414179  [   64/50000]\n",
      "loss: 0.521250  [ 6464/50000]\n",
      "loss: 0.321926  [12864/50000]\n",
      "loss: 0.528354  [19264/50000]\n",
      "loss: 0.539868  [25664/50000]\n",
      "loss: 0.759392  [32064/50000]\n",
      "loss: 0.521581  [38464/50000]\n",
      "loss: 0.545635  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.513009 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.415030  [   64/50000]\n",
      "loss: 0.531626  [ 6464/50000]\n",
      "loss: 0.317140  [12864/50000]\n",
      "loss: 0.534460  [19264/50000]\n",
      "loss: 0.486071  [25664/50000]\n",
      "loss: 0.724380  [32064/50000]\n",
      "loss: 0.558371  [38464/50000]\n",
      "loss: 0.457195  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.516026 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.370707  [   64/50000]\n",
      "loss: 0.487881  [ 6464/50000]\n",
      "loss: 0.323430  [12864/50000]\n",
      "loss: 0.574176  [19264/50000]\n",
      "loss: 0.563114  [25664/50000]\n",
      "loss: 0.644999  [32064/50000]\n",
      "loss: 0.504492  [38464/50000]\n",
      "loss: 0.466312  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.513115 \n",
      "\n",
      "Done!\n",
      "Evaluating 56 layer model with activation function: relu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.395766  [   64/50000]\n",
      "loss: 0.544627  [ 6464/50000]\n",
      "loss: 0.441173  [12864/50000]\n",
      "loss: 0.626423  [19264/50000]\n",
      "loss: 0.524947  [25664/50000]\n",
      "loss: 0.688882  [32064/50000]\n",
      "loss: 0.562779  [38464/50000]\n",
      "loss: 0.437360  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514412 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.401092  [   64/50000]\n",
      "loss: 0.495351  [ 6464/50000]\n",
      "loss: 0.382158  [12864/50000]\n",
      "loss: 0.527968  [19264/50000]\n",
      "loss: 0.715746  [25664/50000]\n",
      "loss: 0.735708  [32064/50000]\n",
      "loss: 0.590455  [38464/50000]\n",
      "loss: 0.465798  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514224 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.418984  [   64/50000]\n",
      "loss: 0.530278  [ 6464/50000]\n",
      "loss: 0.336618  [12864/50000]\n",
      "loss: 0.568109  [19264/50000]\n",
      "loss: 0.590011  [25664/50000]\n",
      "loss: 0.682867  [32064/50000]\n",
      "loss: 0.538789  [38464/50000]\n",
      "loss: 0.431130  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.516294 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.342694  [   64/50000]\n",
      "loss: 0.529209  [ 6464/50000]\n",
      "loss: 0.353714  [12864/50000]\n",
      "loss: 0.562262  [19264/50000]\n",
      "loss: 0.650011  [25664/50000]\n",
      "loss: 0.650864  [32064/50000]\n",
      "loss: 0.461945  [38464/50000]\n",
      "loss: 0.455418  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.515057 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.371100  [   64/50000]\n",
      "loss: 0.580517  [ 6464/50000]\n",
      "loss: 0.297741  [12864/50000]\n",
      "loss: 0.626321  [19264/50000]\n",
      "loss: 0.518940  [25664/50000]\n",
      "loss: 0.793802  [32064/50000]\n",
      "loss: 0.506425  [38464/50000]\n",
      "loss: 0.514320  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514122 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.417789  [   64/50000]\n",
      "loss: 0.512835  [ 6464/50000]\n",
      "loss: 0.358629  [12864/50000]\n",
      "loss: 0.538943  [19264/50000]\n",
      "loss: 0.545275  [25664/50000]\n",
      "loss: 0.717659  [32064/50000]\n",
      "loss: 0.494540  [38464/50000]\n",
      "loss: 0.419817  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514352 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.427516  [   64/50000]\n",
      "loss: 0.454551  [ 6464/50000]\n",
      "loss: 0.356758  [12864/50000]\n",
      "loss: 0.518855  [19264/50000]\n",
      "loss: 0.531976  [25664/50000]\n",
      "loss: 0.762791  [32064/50000]\n",
      "loss: 0.501249  [38464/50000]\n",
      "loss: 0.518220  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.513382 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.509706  [   64/50000]\n",
      "loss: 0.465519  [ 6464/50000]\n",
      "loss: 0.330521  [12864/50000]\n",
      "loss: 0.598699  [19264/50000]\n",
      "loss: 0.511372  [25664/50000]\n",
      "loss: 0.699728  [32064/50000]\n",
      "loss: 0.496192  [38464/50000]\n",
      "loss: 0.443156  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.513649 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.474989  [   64/50000]\n",
      "loss: 0.493086  [ 6464/50000]\n",
      "loss: 0.346992  [12864/50000]\n",
      "loss: 0.586824  [19264/50000]\n",
      "loss: 0.531130  [25664/50000]\n",
      "loss: 0.714898  [32064/50000]\n",
      "loss: 0.535483  [38464/50000]\n",
      "loss: 0.512062  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.513661 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.376189  [   64/50000]\n",
      "loss: 0.521510  [ 6464/50000]\n",
      "loss: 0.302360  [12864/50000]\n",
      "loss: 0.606670  [19264/50000]\n",
      "loss: 0.519294  [25664/50000]\n",
      "loss: 0.658481  [32064/50000]\n",
      "loss: 0.564901  [38464/50000]\n",
      "loss: 0.512762  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.512464 \n",
      "\n",
      "Done!\n",
      "Evaluating 56 layer model with activation function: silu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.495793  [   64/50000]\n",
      "loss: 0.575997  [ 6464/50000]\n",
      "loss: 0.342741  [12864/50000]\n",
      "loss: 0.558440  [19264/50000]\n",
      "loss: 0.474978  [25664/50000]\n",
      "loss: 0.632342  [32064/50000]\n",
      "loss: 0.479289  [38464/50000]\n",
      "loss: 0.474896  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514159 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.461804  [   64/50000]\n",
      "loss: 0.511215  [ 6464/50000]\n",
      "loss: 0.306888  [12864/50000]\n",
      "loss: 0.611786  [19264/50000]\n",
      "loss: 0.531490  [25664/50000]\n",
      "loss: 0.755860  [32064/50000]\n",
      "loss: 0.544143  [38464/50000]\n",
      "loss: 0.517597  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514129 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.372072  [   64/50000]\n",
      "loss: 0.518657  [ 6464/50000]\n",
      "loss: 0.394777  [12864/50000]\n",
      "loss: 0.519923  [19264/50000]\n",
      "loss: 0.501520  [25664/50000]\n",
      "loss: 0.642676  [32064/50000]\n",
      "loss: 0.491708  [38464/50000]\n",
      "loss: 0.435672  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514009 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.411751  [   64/50000]\n",
      "loss: 0.510137  [ 6464/50000]\n",
      "loss: 0.291101  [12864/50000]\n",
      "loss: 0.504665  [19264/50000]\n",
      "loss: 0.486416  [25664/50000]\n",
      "loss: 0.778072  [32064/50000]\n",
      "loss: 0.565909  [38464/50000]\n",
      "loss: 0.582252  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514768 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.449950  [   64/50000]\n",
      "loss: 0.474556  [ 6464/50000]\n",
      "loss: 0.368579  [12864/50000]\n",
      "loss: 0.537198  [19264/50000]\n",
      "loss: 0.548909  [25664/50000]\n",
      "loss: 0.751850  [32064/50000]\n",
      "loss: 0.469199  [38464/50000]\n",
      "loss: 0.546555  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.513259 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.496325  [   64/50000]\n",
      "loss: 0.547471  [ 6464/50000]\n",
      "loss: 0.287834  [12864/50000]\n",
      "loss: 0.613922  [19264/50000]\n",
      "loss: 0.446328  [25664/50000]\n",
      "loss: 0.844155  [32064/50000]\n",
      "loss: 0.521452  [38464/50000]\n",
      "loss: 0.458637  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515116 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.456720  [   64/50000]\n",
      "loss: 0.521286  [ 6464/50000]\n",
      "loss: 0.384318  [12864/50000]\n",
      "loss: 0.525847  [19264/50000]\n",
      "loss: 0.503941  [25664/50000]\n",
      "loss: 0.736567  [32064/50000]\n",
      "loss: 0.592146  [38464/50000]\n",
      "loss: 0.515317  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514820 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.405869  [   64/50000]\n",
      "loss: 0.494980  [ 6464/50000]\n",
      "loss: 0.386466  [12864/50000]\n",
      "loss: 0.566813  [19264/50000]\n",
      "loss: 0.393564  [25664/50000]\n",
      "loss: 0.688108  [32064/50000]\n",
      "loss: 0.640296  [38464/50000]\n",
      "loss: 0.425706  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515725 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.408934  [   64/50000]\n",
      "loss: 0.523723  [ 6464/50000]\n",
      "loss: 0.335116  [12864/50000]\n",
      "loss: 0.603065  [19264/50000]\n",
      "loss: 0.449686  [25664/50000]\n",
      "loss: 0.818120  [32064/50000]\n",
      "loss: 0.617355  [38464/50000]\n",
      "loss: 0.460314  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514372 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.503386  [   64/50000]\n",
      "loss: 0.554619  [ 6464/50000]\n",
      "loss: 0.385218  [12864/50000]\n",
      "loss: 0.566980  [19264/50000]\n",
      "loss: 0.550666  [25664/50000]\n",
      "loss: 0.617494  [32064/50000]\n",
      "loss: 0.554357  [38464/50000]\n",
      "loss: 0.534678  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514468 \n",
      "\n",
      "Done!\n",
      "Evaluating 56 layer model with activation function: max_x_sigmoid\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.391089  [   64/50000]\n",
      "loss: 0.534966  [ 6464/50000]\n",
      "loss: 0.355802  [12864/50000]\n",
      "loss: 0.536935  [19264/50000]\n",
      "loss: 0.607445  [25664/50000]\n",
      "loss: 0.699480  [32064/50000]\n",
      "loss: 0.515540  [38464/50000]\n",
      "loss: 0.487763  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514216 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.365561  [   64/50000]\n",
      "loss: 0.529287  [ 6464/50000]\n",
      "loss: 0.334269  [12864/50000]\n",
      "loss: 0.478676  [19264/50000]\n",
      "loss: 0.534210  [25664/50000]\n",
      "loss: 0.787291  [32064/50000]\n",
      "loss: 0.480988  [38464/50000]\n",
      "loss: 0.489695  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.515046 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.449610  [   64/50000]\n",
      "loss: 0.469297  [ 6464/50000]\n",
      "loss: 0.365024  [12864/50000]\n",
      "loss: 0.607891  [19264/50000]\n",
      "loss: 0.633229  [25664/50000]\n",
      "loss: 0.786097  [32064/50000]\n",
      "loss: 0.575029  [38464/50000]\n",
      "loss: 0.483535  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.513448 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.378412  [   64/50000]\n",
      "loss: 0.496081  [ 6464/50000]\n",
      "loss: 0.360704  [12864/50000]\n",
      "loss: 0.591837  [19264/50000]\n",
      "loss: 0.518340  [25664/50000]\n",
      "loss: 0.673878  [32064/50000]\n",
      "loss: 0.606905  [38464/50000]\n",
      "loss: 0.441245  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514199 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.351366  [   64/50000]\n",
      "loss: 0.496283  [ 6464/50000]\n",
      "loss: 0.373062  [12864/50000]\n",
      "loss: 0.552393  [19264/50000]\n",
      "loss: 0.467697  [25664/50000]\n",
      "loss: 0.691853  [32064/50000]\n",
      "loss: 0.528893  [38464/50000]\n",
      "loss: 0.468311  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.512178 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.381718  [   64/50000]\n",
      "loss: 0.558291  [ 6464/50000]\n",
      "loss: 0.400614  [12864/50000]\n",
      "loss: 0.500904  [19264/50000]\n",
      "loss: 0.580406  [25664/50000]\n",
      "loss: 0.773965  [32064/50000]\n",
      "loss: 0.529757  [38464/50000]\n",
      "loss: 0.452071  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.515470 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.372452  [   64/50000]\n",
      "loss: 0.527475  [ 6464/50000]\n",
      "loss: 0.258794  [12864/50000]\n",
      "loss: 0.468306  [19264/50000]\n",
      "loss: 0.492096  [25664/50000]\n",
      "loss: 0.677770  [32064/50000]\n",
      "loss: 0.497737  [38464/50000]\n",
      "loss: 0.498670  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.515046 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.434425  [   64/50000]\n",
      "loss: 0.540118  [ 6464/50000]\n",
      "loss: 0.332405  [12864/50000]\n",
      "loss: 0.553550  [19264/50000]\n",
      "loss: 0.534315  [25664/50000]\n",
      "loss: 0.695161  [32064/50000]\n",
      "loss: 0.508715  [38464/50000]\n",
      "loss: 0.468236  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514840 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.488070  [   64/50000]\n",
      "loss: 0.496419  [ 6464/50000]\n",
      "loss: 0.301080  [12864/50000]\n",
      "loss: 0.610666  [19264/50000]\n",
      "loss: 0.586537  [25664/50000]\n",
      "loss: 0.775999  [32064/50000]\n",
      "loss: 0.535182  [38464/50000]\n",
      "loss: 0.471920  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.513772 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.340976  [   64/50000]\n",
      "loss: 0.478828  [ 6464/50000]\n",
      "loss: 0.387292  [12864/50000]\n",
      "loss: 0.553923  [19264/50000]\n",
      "loss: 0.597309  [25664/50000]\n",
      "loss: 0.750279  [32064/50000]\n",
      "loss: 0.445274  [38464/50000]\n",
      "loss: 0.490016  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.516105 \n",
      "\n",
      "Done!\n",
      "Evaluating 56 layer model with activation function: cosx_minus_x\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.456018  [   64/50000]\n",
      "loss: 0.528693  [ 6464/50000]\n",
      "loss: 0.423630  [12864/50000]\n",
      "loss: 0.572897  [19264/50000]\n",
      "loss: 0.526620  [25664/50000]\n",
      "loss: 0.680359  [32064/50000]\n",
      "loss: 0.508478  [38464/50000]\n",
      "loss: 0.561057  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514263 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.463211  [   64/50000]\n",
      "loss: 0.440680  [ 6464/50000]\n",
      "loss: 0.339405  [12864/50000]\n",
      "loss: 0.544643  [19264/50000]\n",
      "loss: 0.534141  [25664/50000]\n",
      "loss: 0.728618  [32064/50000]\n",
      "loss: 0.497286  [38464/50000]\n",
      "loss: 0.435448  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514595 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.355726  [   64/50000]\n",
      "loss: 0.541962  [ 6464/50000]\n",
      "loss: 0.377954  [12864/50000]\n",
      "loss: 0.554029  [19264/50000]\n",
      "loss: 0.565444  [25664/50000]\n",
      "loss: 0.688052  [32064/50000]\n",
      "loss: 0.499933  [38464/50000]\n",
      "loss: 0.455467  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.516358 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.406595  [   64/50000]\n",
      "loss: 0.438167  [ 6464/50000]\n",
      "loss: 0.295576  [12864/50000]\n",
      "loss: 0.626820  [19264/50000]\n",
      "loss: 0.527417  [25664/50000]\n",
      "loss: 0.730368  [32064/50000]\n",
      "loss: 0.484359  [38464/50000]\n",
      "loss: 0.501536  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.513107 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.344608  [   64/50000]\n",
      "loss: 0.530760  [ 6464/50000]\n",
      "loss: 0.380860  [12864/50000]\n",
      "loss: 0.594680  [19264/50000]\n",
      "loss: 0.527149  [25664/50000]\n",
      "loss: 0.724816  [32064/50000]\n",
      "loss: 0.452597  [38464/50000]\n",
      "loss: 0.470869  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.514604 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.440285  [   64/50000]\n",
      "loss: 0.523502  [ 6464/50000]\n",
      "loss: 0.303135  [12864/50000]\n",
      "loss: 0.556029  [19264/50000]\n",
      "loss: 0.441827  [25664/50000]\n",
      "loss: 0.802498  [32064/50000]\n",
      "loss: 0.470730  [38464/50000]\n",
      "loss: 0.398060  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.512604 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.406487  [   64/50000]\n",
      "loss: 0.526698  [ 6464/50000]\n",
      "loss: 0.417542  [12864/50000]\n",
      "loss: 0.580308  [19264/50000]\n",
      "loss: 0.550260  [25664/50000]\n",
      "loss: 0.830448  [32064/50000]\n",
      "loss: 0.402673  [38464/50000]\n",
      "loss: 0.464118  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.516088 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.437017  [   64/50000]\n",
      "loss: 0.517690  [ 6464/50000]\n",
      "loss: 0.316338  [12864/50000]\n",
      "loss: 0.638720  [19264/50000]\n",
      "loss: 0.577097  [25664/50000]\n",
      "loss: 0.706236  [32064/50000]\n",
      "loss: 0.534579  [38464/50000]\n",
      "loss: 0.494705  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515771 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.296582  [   64/50000]\n",
      "loss: 0.492607  [ 6464/50000]\n",
      "loss: 0.318803  [12864/50000]\n",
      "loss: 0.578580  [19264/50000]\n",
      "loss: 0.546629  [25664/50000]\n",
      "loss: 0.804683  [32064/50000]\n",
      "loss: 0.459918  [38464/50000]\n",
      "loss: 0.450205  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.513944 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.462876  [   64/50000]\n",
      "loss: 0.464309  [ 6464/50000]\n",
      "loss: 0.374566  [12864/50000]\n",
      "loss: 0.472421  [19264/50000]\n",
      "loss: 0.628697  [25664/50000]\n",
      "loss: 0.749148  [32064/50000]\n",
      "loss: 0.610608  [38464/50000]\n",
      "loss: 0.452921  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515235 \n",
      "\n",
      "Done!\n",
      "Evaluating 56 layer model with activation function: lrelu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.387401  [   64/50000]\n",
      "loss: 0.490904  [ 6464/50000]\n",
      "loss: 0.328491  [12864/50000]\n",
      "loss: 0.554578  [19264/50000]\n",
      "loss: 0.541291  [25664/50000]\n",
      "loss: 0.687415  [32064/50000]\n",
      "loss: 0.541962  [38464/50000]\n",
      "loss: 0.513724  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.514741 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.433101  [   64/50000]\n",
      "loss: 0.526558  [ 6464/50000]\n",
      "loss: 0.323858  [12864/50000]\n",
      "loss: 0.499995  [19264/50000]\n",
      "loss: 0.569262  [25664/50000]\n",
      "loss: 0.714312  [32064/50000]\n",
      "loss: 0.502612  [38464/50000]\n",
      "loss: 0.515318  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.513692 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.370064  [   64/50000]\n",
      "loss: 0.473500  [ 6464/50000]\n",
      "loss: 0.279251  [12864/50000]\n",
      "loss: 0.517043  [19264/50000]\n",
      "loss: 0.573667  [25664/50000]\n",
      "loss: 0.930679  [32064/50000]\n",
      "loss: 0.529749  [38464/50000]\n",
      "loss: 0.463984  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515621 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.403352  [   64/50000]\n",
      "loss: 0.441385  [ 6464/50000]\n",
      "loss: 0.386454  [12864/50000]\n",
      "loss: 0.605084  [19264/50000]\n",
      "loss: 0.528295  [25664/50000]\n",
      "loss: 0.771926  [32064/50000]\n",
      "loss: 0.572976  [38464/50000]\n",
      "loss: 0.573192  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.514022 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.400578  [   64/50000]\n",
      "loss: 0.486273  [ 6464/50000]\n",
      "loss: 0.296975  [12864/50000]\n",
      "loss: 0.568705  [19264/50000]\n",
      "loss: 0.551484  [25664/50000]\n",
      "loss: 0.732398  [32064/50000]\n",
      "loss: 0.541152  [38464/50000]\n",
      "loss: 0.502516  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514384 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.399716  [   64/50000]\n",
      "loss: 0.528204  [ 6464/50000]\n",
      "loss: 0.342330  [12864/50000]\n",
      "loss: 0.508761  [19264/50000]\n",
      "loss: 0.565717  [25664/50000]\n",
      "loss: 0.678177  [32064/50000]\n",
      "loss: 0.504677  [38464/50000]\n",
      "loss: 0.438042  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.513935 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.368294  [   64/50000]\n",
      "loss: 0.491592  [ 6464/50000]\n",
      "loss: 0.365072  [12864/50000]\n",
      "loss: 0.586031  [19264/50000]\n",
      "loss: 0.654198  [25664/50000]\n",
      "loss: 0.766082  [32064/50000]\n",
      "loss: 0.607269  [38464/50000]\n",
      "loss: 0.444221  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.513398 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.343596  [   64/50000]\n",
      "loss: 0.447272  [ 6464/50000]\n",
      "loss: 0.406245  [12864/50000]\n",
      "loss: 0.534756  [19264/50000]\n",
      "loss: 0.581937  [25664/50000]\n",
      "loss: 0.711353  [32064/50000]\n",
      "loss: 0.415334  [38464/50000]\n",
      "loss: 0.433428  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.512995 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.358548  [   64/50000]\n",
      "loss: 0.453964  [ 6464/50000]\n",
      "loss: 0.282394  [12864/50000]\n",
      "loss: 0.457129  [19264/50000]\n",
      "loss: 0.623364  [25664/50000]\n",
      "loss: 0.668720  [32064/50000]\n",
      "loss: 0.529431  [38464/50000]\n",
      "loss: 0.535938  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514341 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.430449  [   64/50000]\n",
      "loss: 0.523957  [ 6464/50000]\n",
      "loss: 0.334400  [12864/50000]\n",
      "loss: 0.545815  [19264/50000]\n",
      "loss: 0.598977  [25664/50000]\n",
      "loss: 0.693875  [32064/50000]\n",
      "loss: 0.523199  [38464/50000]\n",
      "loss: 0.409400  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.513086 \n",
      "\n",
      "Done!\n",
      "Evaluating 56 layer model with activation function: prelu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.403173  [   64/50000]\n",
      "loss: 0.531894  [ 6464/50000]\n",
      "loss: 0.343823  [12864/50000]\n",
      "loss: 0.483094  [19264/50000]\n",
      "loss: 0.593702  [25664/50000]\n",
      "loss: 0.725227  [32064/50000]\n",
      "loss: 0.502143  [38464/50000]\n",
      "loss: 0.522242  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515060 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.397754  [   64/50000]\n",
      "loss: 0.516606  [ 6464/50000]\n",
      "loss: 0.321701  [12864/50000]\n",
      "loss: 0.577509  [19264/50000]\n",
      "loss: 0.527324  [25664/50000]\n",
      "loss: 0.779448  [32064/50000]\n",
      "loss: 0.526976  [38464/50000]\n",
      "loss: 0.443539  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515490 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.417127  [   64/50000]\n",
      "loss: 0.473317  [ 6464/50000]\n",
      "loss: 0.363498  [12864/50000]\n",
      "loss: 0.603217  [19264/50000]\n",
      "loss: 0.596935  [25664/50000]\n",
      "loss: 0.733400  [32064/50000]\n",
      "loss: 0.542702  [38464/50000]\n",
      "loss: 0.528090  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.513283 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.421698  [   64/50000]\n",
      "loss: 0.456471  [ 6464/50000]\n",
      "loss: 0.406303  [12864/50000]\n",
      "loss: 0.567448  [19264/50000]\n",
      "loss: 0.605210  [25664/50000]\n",
      "loss: 0.717614  [32064/50000]\n",
      "loss: 0.659339  [38464/50000]\n",
      "loss: 0.398033  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514773 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.362118  [   64/50000]\n",
      "loss: 0.511983  [ 6464/50000]\n",
      "loss: 0.356190  [12864/50000]\n",
      "loss: 0.561517  [19264/50000]\n",
      "loss: 0.465400  [25664/50000]\n",
      "loss: 0.817582  [32064/50000]\n",
      "loss: 0.490000  [38464/50000]\n",
      "loss: 0.441626  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.513188 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.402347  [   64/50000]\n",
      "loss: 0.536944  [ 6464/50000]\n",
      "loss: 0.329220  [12864/50000]\n",
      "loss: 0.573877  [19264/50000]\n",
      "loss: 0.567819  [25664/50000]\n",
      "loss: 0.704305  [32064/50000]\n",
      "loss: 0.488529  [38464/50000]\n",
      "loss: 0.432683  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.514834 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.422286  [   64/50000]\n",
      "loss: 0.531826  [ 6464/50000]\n",
      "loss: 0.387218  [12864/50000]\n",
      "loss: 0.500858  [19264/50000]\n",
      "loss: 0.613147  [25664/50000]\n",
      "loss: 0.796397  [32064/50000]\n",
      "loss: 0.535594  [38464/50000]\n",
      "loss: 0.525015  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.514867 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.439645  [   64/50000]\n",
      "loss: 0.477889  [ 6464/50000]\n",
      "loss: 0.324308  [12864/50000]\n",
      "loss: 0.554403  [19264/50000]\n",
      "loss: 0.559436  [25664/50000]\n",
      "loss: 0.653632  [32064/50000]\n",
      "loss: 0.544675  [38464/50000]\n",
      "loss: 0.553177  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514995 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.476307  [   64/50000]\n",
      "loss: 0.474547  [ 6464/50000]\n",
      "loss: 0.334134  [12864/50000]\n",
      "loss: 0.628047  [19264/50000]\n",
      "loss: 0.601093  [25664/50000]\n",
      "loss: 0.702025  [32064/50000]\n",
      "loss: 0.451167  [38464/50000]\n",
      "loss: 0.387361  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514995 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.442579  [   64/50000]\n",
      "loss: 0.496426  [ 6464/50000]\n",
      "loss: 0.322037  [12864/50000]\n",
      "loss: 0.602729  [19264/50000]\n",
      "loss: 0.569997  [25664/50000]\n",
      "loss: 0.783350  [32064/50000]\n",
      "loss: 0.473847  [38464/50000]\n",
      "loss: 0.434708  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514613 \n",
      "\n",
      "Done!\n",
      "Evaluating 56 layer model with activation function: softplus\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.315475  [   64/50000]\n",
      "loss: 0.479221  [ 6464/50000]\n",
      "loss: 0.291881  [12864/50000]\n",
      "loss: 0.601766  [19264/50000]\n",
      "loss: 0.652009  [25664/50000]\n",
      "loss: 0.672165  [32064/50000]\n",
      "loss: 0.516044  [38464/50000]\n",
      "loss: 0.470267  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.513542 \n",
      "\n",
      "Done!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.423167  [   64/50000]\n",
      "loss: 0.516769  [ 6464/50000]\n",
      "loss: 0.298266  [12864/50000]\n",
      "loss: 0.617663  [19264/50000]\n",
      "loss: 0.456137  [25664/50000]\n",
      "loss: 0.773829  [32064/50000]\n",
      "loss: 0.435721  [38464/50000]\n",
      "loss: 0.460151  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.515603 \n",
      "\n",
      "Done!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.392867  [   64/50000]\n",
      "loss: 0.497769  [ 6464/50000]\n",
      "loss: 0.348361  [12864/50000]\n",
      "loss: 0.557039  [19264/50000]\n",
      "loss: 0.565901  [25664/50000]\n",
      "loss: 0.714803  [32064/50000]\n",
      "loss: 0.457729  [38464/50000]\n",
      "loss: 0.460240  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.513353 \n",
      "\n",
      "Done!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.399407  [   64/50000]\n",
      "loss: 0.540259  [ 6464/50000]\n",
      "loss: 0.278870  [12864/50000]\n",
      "loss: 0.521328  [19264/50000]\n",
      "loss: 0.661256  [25664/50000]\n",
      "loss: 0.763473  [32064/50000]\n",
      "loss: 0.522728  [38464/50000]\n",
      "loss: 0.475169  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.516052 \n",
      "\n",
      "Done!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.388324  [   64/50000]\n",
      "loss: 0.494634  [ 6464/50000]\n",
      "loss: 0.395848  [12864/50000]\n",
      "loss: 0.476712  [19264/50000]\n",
      "loss: 0.601840  [25664/50000]\n",
      "loss: 0.815174  [32064/50000]\n",
      "loss: 0.536619  [38464/50000]\n",
      "loss: 0.469489  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.516469 \n",
      "\n",
      "Done!\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.437963  [   64/50000]\n",
      "loss: 0.535453  [ 6464/50000]\n",
      "loss: 0.316744  [12864/50000]\n",
      "loss: 0.526095  [19264/50000]\n",
      "loss: 0.579629  [25664/50000]\n",
      "loss: 0.893510  [32064/50000]\n",
      "loss: 0.503722  [38464/50000]\n",
      "loss: 0.476576  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514051 \n",
      "\n",
      "Done!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.376697  [   64/50000]\n",
      "loss: 0.532775  [ 6464/50000]\n",
      "loss: 0.314048  [12864/50000]\n",
      "loss: 0.618184  [19264/50000]\n",
      "loss: 0.494961  [25664/50000]\n",
      "loss: 0.778142  [32064/50000]\n",
      "loss: 0.543158  [38464/50000]\n",
      "loss: 0.485181  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514446 \n",
      "\n",
      "Done!\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.452794  [   64/50000]\n",
      "loss: 0.530292  [ 6464/50000]\n",
      "loss: 0.359649  [12864/50000]\n",
      "loss: 0.525376  [19264/50000]\n",
      "loss: 0.635772  [25664/50000]\n",
      "loss: 0.753464  [32064/50000]\n",
      "loss: 0.537682  [38464/50000]\n",
      "loss: 0.417590  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.515516 \n",
      "\n",
      "Done!\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.431699  [   64/50000]\n",
      "loss: 0.567225  [ 6464/50000]\n",
      "loss: 0.313806  [12864/50000]\n",
      "loss: 0.590609  [19264/50000]\n",
      "loss: 0.524387  [25664/50000]\n",
      "loss: 0.820368  [32064/50000]\n",
      "loss: 0.562254  [38464/50000]\n",
      "loss: 0.482536  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.513734 \n",
      "\n",
      "Done!\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.390013  [   64/50000]\n",
      "loss: 0.463389  [ 6464/50000]\n",
      "loss: 0.294738  [12864/50000]\n",
      "loss: 0.555270  [19264/50000]\n",
      "loss: 0.506168  [25664/50000]\n",
      "loss: 0.744907  [32064/50000]\n",
      "loss: 0.565375  [38464/50000]\n",
      "loss: 0.551162  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.514264 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for n in model_sizes:\n",
    "    for funcname, function in functions.items():\n",
    "        save_to = f'results/resnet_{6*n+2}_{funcname}.csv'\n",
    "        print(f'Evaluating {6*n+2} layer model with activation function: {funcname}')\n",
    "        if os.path.isfile(save_to):\n",
    "            print(f'Results already generated, skipping')\n",
    "        else:\n",
    "            training_data = datasets.CIFAR10(\n",
    "                root=\"data\",\n",
    "                train=True,\n",
    "                download=True,\n",
    "                transform=train_transform\n",
    "            )\n",
    "\n",
    "            test_data = datasets.CIFAR10(\n",
    "                root=\"data\",\n",
    "                train=False,\n",
    "                download=True,\n",
    "                transform=test_transform\n",
    "            )\n",
    "            train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "            test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "            model = ResNet(function, n)\n",
    "            loss_fn = torch.nn.CrossEntropyLoss()\n",
    "            optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "            results = eval(train_dataloader, test_dataloader, resnet_relu, loss_fn, optimizer, epochs)\n",
    "            results.to_csv(save_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
